---
tags:
  - concept
  - psychology/cognitive_bias
  - logic/fallacies
keywords: 
topics:
  - logic
  - psychology
name: 
date of note: 2024-04-29
---

## Concept Definition

>[!important]
>**Name**:  Neglect of Probability
>
>The **neglect of probability**, a type of [cognitive bias](https://en.wikipedia.org/wiki/Cognitive_bias "Cognitive bias"), is the tendency to *disregard* [probability](https://en.wikipedia.org/wiki/Probability "Probability") when making a decision under *uncertainty* and is one simple way in which people **regularly violate the normative rules** for decision making. *Small risks* are typically either *neglected* entirely or hugely *overrated*. The continuum between the extremes is ignored. The term **probability neglect** was coined by [Cass Sunstein](https://en.wikipedia.org/wiki/Cass_Sunstein "Cass Sunstein").[^1]



## Explanation

>[!quote]
>This illustrates that we respond to the **expected magnitude** of an event (the size of the jackpot or the amount of electricity), but **not** to its **likelihood**. In other words: *We lack an intuitive grasp of probability*.
>-- pp 93, [[The Art of Thinking Clearly Book Summary]]


>[!quote]
>The proper term for this is **"neglect of probability,"** and it leads to errors in decision making. We invest in start-ups because the potential profit makes dollar signs flash before our eyes, but we forget (or are too lazy) to investigate *the slim chances* of new businesses actually achieving such growth. Similarly, following extensive media coverage of a plane crash, we cancel flights without really considering the *minuscule probability* of crashing (which, of course, remains the same before and after such a disaster). Many amateur investors compare their investments solely on the basis of yield. For them, Google shares with a return of 20 percent must be twice as good as property that returns 10 percent. That's wrong. It would be a lot smarter to also consider both **investments' risks**. But then again, **we have no natural feel for this**, so we often turn a blind eye to it.
>-- pp 93, [[The Art of Thinking Clearly Book Summary]]


>[!quote]
>We have **no intuitive grasp of risk** and thus *distinguish poorly among different threats.* The more serious the threat and the more emotional the topic (such as radioactivity), the less reassuring a reduction in risk seems to us. Two researchers at the University of Chicago have shown that people are equally afraid of a 99 percent chance as they are of a 1 percent chance of contamination by toxic chemicals. An irrational response, but a common one.
>-- pp 94, [[The Art of Thinking Clearly Book Summary]]



-----------
##  Recommended Notes and References

- [[The Art of Thinking Clearly Book Summary]]
- [[Thinking, Fast and Slow Book Summary]]

- Wikipedia [Neglect of probability](https://en.wikipedia.org/wiki/Neglect_of_probability)
- Wikipedia [List of cognitive biases](https://en.wikipedia.org/wiki/List_of_cognitive_biases)

[^1]: Kahneman, D. (2011). [Thinking Fast and Slow](https://www.penguin.co.uk/nf/Book/BookDisplay/0,,9780141918921,00.html) [Archived](https://web.archive.org/web/20140731170932/http://www.penguin.co.uk/nf/Book/BookDisplay/0,,9780141918921,00.html) 2014-07-31 at the [Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine "Wayback Machine"), Allen Lane 2011, p. 143 f.