---
tags:
  - entry_point
  - concept
  - optimization/algorithm
  - optimization/theory
keywords: 
topics:
  - optimization
name: 
date of note: 2024-05-12
---

## Concept Definition

### Theory

- [[Concepts and Theorems in Convex Analysis and Convex Optimization Theory]]
- [[Theory and Algorithms for Convex Optimization]]


### Concepts

- [[Constrained Optimization Problem]]
- [[Unconstrained Local Minimization]]
- [[Unconstrained Global Minimization]]
- [[Necessary and Sufficient Condition for Local Minimum of Smooth Function]]
- [[Stationary Point and Singular Point of Smooth Function]]
- [[Convex Optimization Problem]]
- [[Methods of Lagrangian Multipliers]]
- [[Lagrangian Dual Function]]
- [[Lagrange Dual Problem]]
- [[Fenchel Duality Theorem]]
- [[Saddle Point of Lagrangian Function]]
- [[Karush-Kuhn-Tucker Optimality Condition]]

### First-Order Gradient Algorithms

- [[Iterative Descent]]
- [[Gradient Descent Algorithm]]
- [[Line Search Strategies for Optimal Stepsize]]

### Second-Order Gradient Algorithms

- [[Newton Method]]
- [[Secant Equation and Quasi-Newton Methods]]
- [[BFGS Algorithm]]
- [[Limited Memory BFGS]]
- [[Conjugate Gradient Algorithm Linear]]
- [[Conjugate Gradient Algorithm Nonlinear]]
- [[Conjugate Gradient Algorithm Convergence Analysis]]
- [[Conjugate Gradient Algorithm Nonlinear Convergence Analysis]]
- [[Conjugate Gradient Algorithm Lanczos]]
- [[Newton-Conjugate Gradient and Inexact Newton Method]]

### Feasible Direction Method for Constrained Problem

- [[Feasible Direction Method]]
- [[Gradient Projection Method]]
- [[Block Coordinate Descent Algorithm]]

### Trust-Region Method

- [[Trust Region Method]]
- [[Trust Region Newton-Conjugate Gradient Method]]

### Stochastic Optimization Method

- [[Stochastic Gradient Descent Algorithm]]
- [[Stochastic Gradient Descent with Momentum]]
- [[Stochastic Gradient Descent with Nesterov Momentum]]

### Adaptive Stepsize Gradient Method

- [[AdaGrad Algorithm]]
- [[RMSProp Algorithm]]
- [[Adam Algorithm]]


### Gradient Computation

- [[Automatic Differentiation]]
- [[Back-Propagation Algorithm]]

### Least Square Estimation

- [[Linear Regression]]
- [[Least Square Estimation]]
- [[Least Square Estimation Solution and Geometric Interpretation]]
- [[Normal Equations and Newton System of Equations]]
- [[Algorithms for Least Square Estimation Problem]]
- [[Least Square Estimation with QR Factorization]]
- [[Least Square Estimation via Singular Value Decomposition]]
- [[Conjugate Gradient Normal Equation Residual and CGNER]]
- [[GMRES as Regression on Krylov Space]]
- [[Minimal Residuals Algorithm and MINRES]]


### Eigenvalue Problem

- [[Hermitian or Symmetric Matrix]]
- [[Eigenvalue and Eigenvector for Linear Map]]
- [[Eigenspace and Spectrum for Linear Map]]
- [[Spectral Theorem of Self-Adjoint Map and Eigen decomposition]]
- [[Rayleigh Quotient for Eigenvalue Problem]]
- [[Courant-Fischer Minimax Theorem for Eigenvalue Problem]]
- [[Convex Optimization for Eigenvalue Problem]]

#### Iterative Algorithms to Solve Eigenvalue Problem

- [[Power Iteration and Inverse Iteration for General Eigenvalue Problem]]
- [[QR Iteration for General Eigenvalue Problem]]
- [[Hessenburg QR Iteration for Unsymmetric Eigenvalue Problem]]
- [[QR Iteration Practical for General Eigenvalue Problem]]
- [[Symmetric QR Iteration for Symmetric Eigenvalue Problem]]
- [[Rayleigh Quotient Iteration for Symmetric Eigenvalue Problem]]

#### Iterative Algorithms to Solve Large Sparse Eigenvalue Problem

- [[Hessenberg Decomposition of Matrix]]
- [[Arnoldi Iteration for Hessenberg Reduction of Large Matrix]]
- [[Tridiagonal Decomposition of Symmetric Matrix]]
- [[Lanczos Iteration Practical with Reorthogonalization]]

- [[Biorthogonalization Methods]]
- [[Jacobi-Davidson Algorithm to Sparse Eigenvalue Problem]]

### Derivative-Free Optimization

- [[Theory and Algorithms for Gradient-Free Optimization]]
- [[Derivative-Free Optimization]]


### Sequential Quadratic Programming

- [[Quadratic Programming]]
- [[Sequential Quadratic Programming]]
- [[KKT Matrix and KKT System for Optimization]]
- [[Interior Point Method or Barrier Method for Convex Optimization]]


## Explanation





-----------
##  Recommended Notes and References

- [[Theory and Algorithms for Convex Optimization]]

- [[Convex Optimization by Boyd]]
- [[Numerical Optimization by Nocedal]]
- [[Nonlinear Programming by Bertsekas]]
- [[Convex Optimization Algorithms by Bertsekas]]