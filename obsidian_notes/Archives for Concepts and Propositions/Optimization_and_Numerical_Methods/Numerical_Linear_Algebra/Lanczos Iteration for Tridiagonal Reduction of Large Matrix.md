---
tags:
  - concept
  - numerical_methods/numerical_linear_algebra
  - math/matrix_analysis
keywords:
  - lanczos_iteration
  - lanczos_tridiagonalization
topics:
  - numerical_linear_algebra
  - matrix_analysis
name: Lanczos Iteration for Tridiagonal Reduction of Large Matrix
date of note: 2024-09-21
---

## Concept Definition

>[!important]
>**Name**: Lanczos Iteration for Tridiagonal Reduction of Large Matrix

![[Arnoldi Iteration for Hessenberg Reduction of Large Matrix#^0f19e1]]

>[!info]
>Consider the problem of **tridiagonal reduction** of **Hermitian matrix** $$A = QTQ^{*} \iff AQ = QT$$ 
>
>We can represent the above equation in terms of columns of $Q$, i.e. $$A [q_{1}\,{,}\ldots{,}\,q_{n}] = [q_{1}\,{,}\ldots{,}\,q_{n}]\,\left[ T_{i,j} \right]$$ where $T_{\{ i+2:n \},i}  = T_{i, \{ i+2 :n\}}= 0, \quad i=1\,{,}\ldots{,}\,n-2.$ 
>
>Thus we can obtain the following **recurrent equation**
>$$
>A\,q_{i} = T_{i-1,i}\,q_{i-1} + T_{i,i}\,q_{i} + T_{i+1,i}\,q_{i+1} \in \text{span}\{ q_{i-1},\, q_{i},\, q_{i+1} \}
>$$
>The new vector $q_{i+1}$ can be obtained as
>$$
>T_{i+1,i}\,q_{i+1} = A\,q_{i} - T_{i-1,i}\,q_{i-1} - T_{i,i}\,q_{i} 
>$$

- [[Tridiagonal Decomposition of Symmetric Matrix]]

>[!important] Definition
>Consider the task of *thin tridiagonal reduction* of *Hermitian matrix* $$AQ_{k} = Q_{k}\hat{T_{k}} = Q_{k}T_{k} + r_{k}e_{k}^{T}$$ where $Q_{k} = [q_{1}\,{,}\ldots{,}\,q_{k}]$ is the first $k$ columns of *unitary matrix* $Q$ and $\hat{T}_{k}$ is the top-left $(k+1)\times k$ blocks of *Hermitian tridiagonal matrix* $T$ $$\hat{T}_{k} = \left[ \begin{array}{ccccc}\alpha_{1} & \beta_{1} & & 0 \\[5pt] \beta_{1} & \alpha_{2} & \ddots &   \\[5pt]   & \ddots & \ddots &   \beta_{k-1} \\[5pt]  &    & \beta_{k-1} & \alpha_{k}\\[5pt]  0 &    & & \beta_{k}\end{array} \right] = \left[ \begin{array}{c}T_{k} \\ 0 \quad \beta_{k} \end{array} \right]  \in \mathbb{C}^{(k+1)\times k}$$
>- Specifically, we can obtain the following **three-term recurrent equation** $$A\,q_{i} = \beta_{i-1}\,q_{i-1} + \alpha_{i}\,q_{i} + \beta_{i}\,q_{i+1},\quad i=1\,{,}\ldots{,}\,k$$
>- The $(k+1)$-th column of *unitary matrix* $Q$ can be obtained given $Q_{k}$ and $A$: $$\beta_{k}\,q_{k+1} = A q_{k} - \beta_{k-1}\,q_{k-1} - \alpha_{k}\,q_{k}$$
>  
>The **Lanczos iteration** or **Lancsos triangularization**  *iteratively compute* the columns of *unitary matrix* $Q$ $\{ q_{1}, q_{2}\,{,}\ldots{,}\,q_{k}, q_{k+1},\,{}\ldots{}\, \}$ and the entry $\{ \alpha_{i} \}, \{ \beta_{i} \}$ of *tridiagonal matrix* as follow  
>- *Require*: $A\in \mathbb{C}^{n\times n}$ **Hermitian**
>- *Require*: initial random vector $b\in \mathbb{R}^{n}$
>- Initialize $q_{1}$ by **normalization** $$q_{1} = \frac{b}{\lVert b \rVert_{2}}$$
>- Initialize *residual* $r_{0} = 0$, off-diagonal $\beta_{0} = 1$, initial $q_{0} = 0$
>- For $k=1,\,2\,{,}\ldots{,}\,$
>	- Compute the vector in the *range of* $A$ $$v = Aq_{k}$$
>		- We can use $$v= Aq_{k} - \beta_{k-1}q_{k-1}$$ to increase *stability*.
>	- Compute the **diagonal term** $$\alpha_{k} = \left\langle  q_{k}\,,\,v    \right\rangle$$
>		- This is the *Rayleigh quotient* $$\alpha_{k} = R(A, q_{k}) := \left\langle  q_{k}\,,\,Aq_{k}    \right\rangle$$
>	- Compute the **residual** of $v$ after **projecting** onto the span of $q_{k-1}, q_{k}$ $$v \leftarrow v - \beta_{k-1}\,q_{k-1} - \alpha_{k}\,q_{k}$$
>	- Set **off-diagonal term** $\beta_{k}$ as the **norm** of residual $$\beta_{k+1} = \lVert v \rVert_{2}$$
>	- Set $q_{k+1}$ by **normalization** of **residual**  $$q_{k+1} = \frac{v}{\beta_{k}}$$
>	- Terminate if $\beta_{k+1} = 0$.

- [[Rayleigh Quotient for Eigenvalue Problem]]

>[!important] Definition
>The **Lanczos iteration**  is the **Arnoldi iteration** for $A$ Hermitian. Therefore it is simply the **Modified Gram-Schmidt process** that implements 
>$$
>A\,q_{i} = T_{i-1,i}\,q_{i-1} + T_{i,i}\,q_{i} + T_{i+1,i}\,q_{i+1}, \quad i=1\,{,}\ldots{,}\,k\,{,}\ldots{,}\,
>$$
>- The vectors $\{ q_{k} \}$ generated by the *Lanczos process* are called the **Lanczos vectors**.
>- The *Lanczos vectors* form an *orthonormal basis* for the **Krylov space** $$\text{span}\{q_{1}\,{,}\ldots{,}\,q_{k}\} = \text{span}\{q_{1},\, Aq_{1}\,{,}\ldots{,}\, A^{k-1}q_{1} \} =\mathcal{K}(A, q_{1}, k)$$
>- At $k$ iteration, the Arnoldi process solves the equation $$AQ_{k} = Q_{k}T_{k} + r_{k}e_{k}^{T}.$$ 
>	- The decomposition of the above form is called the **Arnoldi decomposition** if
>		- $Q_{k}$ has *orthonormal columns*
>		- $T_{k}\in \mathbb{C}^{k\times k}$ is an *Hermitian tridiagonal matrix*
>		- the *residual is orthogonal to basis* $$Q_{k}^{*}r_{k} = 0$$

- [[Krylov Subspace and Krylov Matrix]]
- [[Modified Gram-Schmidt Algorithm for QR Factorization]]
- [[QR Factorization of Matrix]]
- [[Tridiagonal Bidiagonal and Block Tridiagonal Matrix]]

### Ritz Approximation of Eigenvalues

![[Tridiagonal Decomposition of Symmetric Matrix#^d21ddc]]

>[!important] Definition
>Define the **Ritz values** with respect to $\mathcal{K}(A, q_{1},k)$ as the *eigenvalues* of $T_{k}$ generated at the $k$-th step of the *Lanczos process*. $$\lambda(T_{k}) = \lambda \left(Q_{k}^{*}AQ_{k}\right).$$ 
>- **Ritz values** are used to approximate the *eigenvalues* of $A$
>- We can use **standard symmetric QR iteration** to compute the eigenvalue of Hessenburg matrix (i.e. except for the *iniitial tridiagonal reduction*)

- [[Ritz Pair for Linear Map with respect to Subspace]]
- [[Symmetric QR Iteration for Symmetric Eigenvalue Problem]]

>[!important]
>In particular, based on the **QR factorization** property, the same $Q_{k}$ transforms the *Krylov matrix* $$Q_{k}^{*}K(A, q_{1}, k) = R_{k}$$ We can see that the **eigendecomposition** of $T_{k}$ $$K(A, q_{1}, k)^{T}\,T_{k}\,K(A, q_{1}, k) = \Lambda = \text{diag}(\theta_{1} \,{,}\ldots{,}\,\theta_{k})$$

- [[Tridiagonal Decomposition of Symmetric Matrix]]
- [[Eigenvalue and Eigenvector for Linear Map]]


![[Invariant Subspaces Approximation for Self-Adjoint Matrix#^6a3a8f]]

- [[Invariant Subspaces Approximation for Self-Adjoint Matrix]]

>[!info]
>The subspace approximation theorem states that 
>$$
>\min_{B} \lVert AQ_{k} - Q_{k}B \rVert 
>$$
>has optimal solution $$B= T_{k} = Q_{k}^{*}AQ_{k}.$$
>Thus, the $\{\theta_{1}\,{,}\ldots{,}\,\theta_{k}\}$ are the *eigenvalues of a "best possible matrix"* that happens to be tridiagonal.


## Explanation

>[!info]
>The **Lanczos iteration** is the **Arnoldi iteration** specialized for **Hermitian case**.

![[Arnoldi Iteration for Hessenberg Reduction of Large Matrix#^d58c5f]]

- [[Arnoldi Iteration for Hessenberg Reduction of Large Matrix]]


>[!info]
>**Lanczos process** is an iterative process that compute **tridiagonal decomposition** of *Hermitian matrix* using **modified Gram-Schmdit** process.
>- **Lanczos proces** is a stable version of **QR factorization** of *Krylov matrix* $$K(A, q_{1}, k)= Q_{k}R_{k}$$
>	- It can be seen as a process of **tridiagonal orthogonalization.**
>- The *eigenvalue* is **approximated** by the *eigenvalue of tridiagonal matrix* at the end of iteration.
>- **Lanczos process** reduce the complexity of the direct tridiagonalization via *Householder transformation*  [[Tridiagonal Reduction of Symmetric Matrix via Householder Transformation]]


|                              | $A = QR$ <br>**QR Factorization**                                      | $A= QTQ^{*}$ <br>**Tridiagonal Factorization**                                                                     |
| ---------------------------- | ---------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| Orthogonal Structuring       | **Householder Transformation**<br><br>[[Householder QR Factorization]] | **Householder Transformation**<br><br>[[Tridiagonal Reduction of Symmetric Matrix via Householder Transformation]] |
| Structured Orthogonalization | **Gram-Schmidt process**<br><br>[[Gram-Schmidt Orthogonalization]]     | **Lanczos process**<br><br>[[Lanczos Iteration for Tridiagonal Reduction of Large Matrix]]                         |






-----------
##  Recommended Notes and References

- [[Tridiagonal Reduction of Symmetric Matrix via Householder Transformation]]

- [[Lanczos Iteration Practical with Reorthogonalization]]
- [[Tridiagonal Bidiagonal and Block Tridiagonal Matrix]]
- [[Tridiagonal Eigenvalue Problem]]




- [[Eigenvalue and Eigenvector for Linear Map]]
- [[Eigenspace and Spectrum for Linear Map]]
- [[Spectral Theorem of Self-Adjoint Map and Eigen decomposition]]
- [[Positive Semidefinite Transformation]]


- [[Matrix Analysis by Horn]] pp 221
- [[Matrix Computations by Golub]] pp 546 - 554, 556 - 571
- [[Numerical Linear Algebra by Trefethen]] pp 276 - 293