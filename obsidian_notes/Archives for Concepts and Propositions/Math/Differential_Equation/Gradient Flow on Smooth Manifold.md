---
tags:
  - concept
  - math/differential_equation
  - math/differential_geometry
  - optimization/theory
  - optimization/algorithm
  - deep_learning/generative_models
keywords: 
topics: 
name: 
date of note: 2024-10-25
---

## Concept Definition

>[!important]
>**Name**: 

- [[Continuity Equation and Gradient Flow on Euclidean Space]]


- [[Smooth Manifold]]
- [[Space of Bounded Signed Measures]]
- [[Divergence Operator of Vector Field on Riemannian Manifold]]
- [[Tangent Space as Finite Dimensional Vector Space]]

- [[Wasserstein Space]]
- [[Wasserstein Distance]]



## Explanation





-----------
##  Recommended Notes and References




- [[Optimal Transport in Space of Measures]]


- [[Stochastic Gradient Descent Algorithm]]
- [[Gradient Descent Algorithm]]
- [[Langevin Dynamics and Langevin Sampling]]

- [[Fokker–Planck Equation via Wasserstein Distance]]
- [[Fokker–Planck and Kolmogorov Forward-Backward Equation]]

- [[Polish Space]]

- [[Tangent Bundle]]
- [[Riemannian Metric and Riemannian Manifold]]
- [[Ordinary Differential Equations]]


- [[Gradient Flows in Metric Spaces and in Space of Probability Measures by Ambrosio]]
- [[An Introduction to Optimization on Smooth Manifolds by Boumal]]
- [[Optimal Transport for Applied Mathematicians by Santambrogio]]
- [[Ordinary Differential Equations by Chicone]]

- Wibisono, A. (2018, July). Sampling as optimization in the space of measures: The Langevin dynamics as a composite optimization problem. In _Conference on Learning Theory_ (pp. 2093-3027). PMLR.