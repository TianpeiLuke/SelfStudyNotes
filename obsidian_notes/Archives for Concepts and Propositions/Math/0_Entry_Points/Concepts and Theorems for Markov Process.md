---
tags:
  - entry_point
  - concept
  - math/stochastic_process
  - math/probability
  - math/functional_analysis
  - statistics/concentration_inequality
  - statistics/monte_carlo_simulation
keywords: 
topics:
  - stochastic_process
  - probability
  - functional_analysis
  - concentration_inequality
  - monte_carlo
name: Markov Chain
date of note: 2024-05-30
---

## Concept Definition

### Basic Concepts

- [[Concepts and Theorems in Probability Theory]]

- [[Markov Chain and Markov Process]]
- [[Markov Transition Kernel and Transition Function]]
- [[Chapman-Kolmogorov Equation]]

- [[Semigroup associated with Transition Function]]
- [[Feller Property of Transition Function]]
- [[Integral Operator associated with Transition Kernel]]

- [[Atom of Markov Chain]]
- [[Small Set of Markov Chain]]

### Stopping Time

- [[Stopping Time of Markov Chain]]
- [[Strong Markov Property]]
- [[Number of Passages and Probability of Finite Return]]
- [[Recursion Formulas for Discrete State Markov Chain]]
- [[Renewal Time of Markov Chain]]

### Martingale Theory

- [[Concepts and Theorems for Martingale]]

### Classification of States for Discrete Time Markov Chain

- [[Communicate as Equivalence State Relation for Markov Chain]]
- [[Classification of States of Markov Chain]]

### Irreducibility and Classification of Discrete Time Markov Chain

- [[Resolvent associated with Transition Kernel]]
- [[Irreducibility of Markov Chain]]
- [[Recurrent Markov Chain]]
- [[Harris Recurrent Set and Harris Recurrent Markov Chain]]
- [[Positive Recurrent Markov Chain]]

- [[Foster Theorem for Discrete State Markov Chain]]
- [[Poke Lemma for Discrete State Markov Chain]]

### Invariant Measure

- [[Invariant Measure and Stationary Distribution]]
- [[Global Balance Equation for Invariant Measure]]
- [[Positive Recurrent Markov Chain]]
- [[Kac Theorem on Markov Chain]]

### Ergodicity

- [[Periodicity of State of Markov Chain]]
- [[Aperiodic Markov Chain]]
- [[Ergodic Markov Chain and Asymptotic of Transition Kernel]]
- [[Fundamental Matrix for Finite State Markov Chain]]

### Ergodic Theorems

- [[Measure Preserving Transformation in Markov Chain]]
- [[Markov Kernel with Invariant Measure via Measure Preserving Map]]
- [[Mixing of Measure Preserving Transformation]]
- [[Ergodic Theorem]]
- [[Ergodic Theorem for Positive Recurrent Markov Process]]
- [[Geometric Ergodicity]]
- [[Geometric Ergodic Theorem]]

### Nonnegative Matrix and Stochastic Matrix Theory

- [[Nonnegative and Positive Matrix]]
- [[Irreducible Nonnegative Matrix]]
- [[Perron-Frobenius Theorem on Irreducible Nonnegative Matrix]]

- [[Stochastic Matrix and Doubly Stochastic Matrix]]
- [[Space of Stochastic Matrices]]
- [[Birkhoff Theorem on Characterization of Doubly Stochastic Matrix]]
- [[Convex Optimization on Space of Double Stochastic Matrices]]


### Time-Reversible Markov Chain

- [[Detailed Balance Equation]]
- [[Time-Reversible Markov Chain]]

### Time-Homogeneous Markov Chain

- [[Stationary Process]]
- [[Time-Homogeneous Markov Process]]

### Central Limit Theorem for Markov Chain

- [[Central Limit Theorem for Discrete State Markov Chains]]
- [[Central Limit Theorem for Reversible Markov Chains]]


### Generator of Continuous Time Markov Chain

- [[Semigroup associated with Transition Function]]
- [[Feller Property of Transition Function]]
- [[Infinitesimal Generator of Markov Process]]

### Diffusion Process

- [[Concepts and Theorems for Stochastic Differential Equations]]
- [[Diffusion Process]]
- [[Fokker–Planck and Kolmogorov Forward-Backward Equation]]
- [[Dynkin Formula]]
- [[Feynman-Kac Formula]]
- [[Martingale via Solution of SDE and Backward Equation]]

### Renewal Process

- [[Renewal Time of Markov Chain]]
- [[Atom of Markov Chain]]
- [[Small Set of Markov Chain]]


### Markov Chain Monte Carlo 

- [[Concepts and Algorithms for Monte Carlo Methods]]

- [[Markov Chain Monte Carlo Methods]]
- [[Metropolis-Hastings Algorithm]]
- [[Random Walk Metropolis-Hastings]]
- [[Gibbs Sampling]]
- [[Hamiltonian Monte Carlo]]
- [[Langevin Dynamics and Langevin Sampling]]
- [[Annealed Importance Sampling]]

### Markov Decision Process and Dynamic Programming

- [[Models and Algorithms for Reinforcement Learning]]

- [[Markov Decision Process]]
- [[Returns and Goals of Reinforcement Learning]]
- [[Value Function and Bellman Equation for MDP]]
- [[Bellman Optimality Equation for MDP]]



## Explanation





-----------
##  Recommended Notes and References


- [[Concepts and Theorems for Stochastic Process]]
- [[Concepts and Theorems for Martingale]]
- [[Concepts and Theorems in Hilbert Space]]



- Halmos, P. R. (2017). _Lectures on ergodic theory_. Courier Dover Publications.
- Friedman, A. (1975). *Stochastic differential equations and applications*. Vol.1
- [[Monte Carlo Statistical Methods by Robert]]
- [[Introduction to Stochastic Calculus by Klebaner]]
- [[A Probability Path by Resnick]]
- [[Probability and Measure by Billingsley]]

- [[Reinforcement Learning An Introduction by Sutton]]


- Wikipedia [Stochastic process](https://en.wikipedia.org/wiki/Stochastic_process)