---
tags:
  - concept
  - math/stochastic_process
  - math/differential_equation
keywords:
  - stochastic_differential_equations
topics:
  - stochastic_process
name: Stochastic Differential Equations
date of note: 2024-06-07
---

## Concept Definition

>[!important]
>**Name**: Stochastic Differential Equations

>[!important] Definition
>Let $(W_{t}) := ((W_{t}^1 \,{,}\ldots{,}\, W_{t}^m))$ be $m$-dimensional *Brownian motion* and $X_{0}$ be an $n$-dimensional *random vector*.
>
>- Define a *filtration*  $(\mathscr{F}_{t})$ where $$\mathscr{F}_{t} = \sigma\left(X_{0}, W_{s}, s\le t \right),$$ that is, $\mathscr{F}_{t}$ is generated by $X_{0}$ and all history of the Brownian motion $W_{s}$ up to time $t$. 
>- Assume $T >0$,  and define a function $$b: \mathbb{R}^n \times [0,T] \to \mathbb{R}^n$$ and $$A: \mathbb{R}^n \times [0,T] \to \mathbb{M}^{n\times m}$$ where $\mathbb{M}^{n\times m}$ denotes the space of $n\times m$ dimensional *progressively measurable stochastic process*. 
>	- Denote each *component function* of $b$ as $b^i,$  where $i=1 \,{,}\ldots{,}\,n$;  
>	- Denote each *component function* of $A$ as $A^{i,j}$, where $i=1 \,{,}\ldots{,}\,n$ and $j=1 \,{,}\ldots{,}\,m.$
>
>We say that a $n$-dimensional *stochastic process* $X_{t}:= X(t)$ is the *solution* the **Itô stochastic differential equation**
>$$
>\left\{ 
>\begin{align*}
>dX(t) &= b\left( X(t), t\right)\,dt + A\left( X(t), t \right)\,dW\\
>X(0)&= X_{0}
>\end{align*}
>\right.
>$$
>for $t\in [0,T]$, provided that  
>- $(X_{t})$ is **progressively measurable** with respect to $(\mathcal{F}_{t})$,
>- $F_{t}:= b\left( X_{t}, t\right) \in \mathbb{L}_{n}^{1}(0,T)$ is a $n$-dimensional **progressively measurable stochastic process,**
>- $G_{t}:= A\left( X_{t}, t\right) \in \mathbb{L}_{n\times m}^{2}(0,T)$ is a $(n\times m)$-dimensional **progressively measurable stochastic process,**
>- and, for all $t\in[0,T]$, 
>  $$
>  X_{t} = X_{0} + \int_{0}^{t}b\left( X_{t}, t\right)\,dt + \int_{0}^{t}A\left( X_{t}, t \right)\,dW.
> $$

^dda568

- [[Stochastic Differential]]
- [[Progressively Measurable Stochastic Process]]
- [[Itô Stochastic Integration]]


## Explanation

>[!important]
>We can understand the role of these terms physicially 
>$$
>dX(t) = b\left( X(t), t\right)\,dt + A\left( X(t), t \right)\,dW
>$$
>- the term $b\left( X(t), t\right)\,dt$ serves as the **drift term**. The drift term is *deterministic* as in ODE. 
>	- Note that the drift term determines the **expectation** of the **increment** of process at infinitesimal time.
>- the term $A\left( X(t), t \right)\,dW$ serves as the **diffusion term**. The diffusion term is *stochastic*. 
>	- This term is also called a **multiplicative noise** since the signal $X_{t}$ multiplying with the white noise $dW$.
>  
>The solution $X_{t}$ is **martingale** if the *drift term* $b \equiv {0}.$  

>[!info]
>A heuristic is to understand that within a small time interval, the process described by SDE follows $$\mathcal{N}\left( b(X_{t},t)\;, \; A^2(X(t), t)\right)$$

>[!info]
>In standard textbook, it is common to write the SDE as
>$$
>dX_{t} = \mu(X_{t}, t)dt + \sigma(X_{t}, t)dW
>$$
>We may use notation $\mu(x, t)$ to indicate the *drift coefficient*, as it corresponds to the *expectation* of Gaussian increments.
>
>Similarly, we use $\sigma^2(x, t)$ to indicate the *diffusion terms* as $\sigma^2$ is commonly used as *the variance* of the Gaussian increment.


>[!important] Discrete Time Stochastic Equation
>For a **discrete-time stochastic process** $\boldsymbol{X} := (X_{t}, t=1,2 \,{,}\ldots{,}\,)$, the stochastic differential equation can be see as a simpler form
>$$
>\begin{align*}
>\boldsymbol{X}_{t+1} - \boldsymbol{X}_{t} &=  \boldsymbol{b}\left(\boldsymbol{X}_{t}, t\right) + \boldsymbol{A}\left(\boldsymbol{X}_{t}, t\right)\,\boldsymbol{\xi}_{t}.
>\end{align*}
>$$
>or, equivalently,
>$$
>\boldsymbol{X}_{t+1}  =  \boldsymbol{X}_{t} +  \boldsymbol{b}\left(\boldsymbol{X}_{t}, t\right) + \boldsymbol{A}\left(\boldsymbol{X}_{t}, t\right)\,\boldsymbol{\xi}_{t}
>$$
>where $\left\{ \boldsymbol{ \xi }_{t}, t=1 \,{,}\ldots{,}\, \right\}\subset \mathbb{R}^m$ are *i.i.d* with $\mathcal{N}(\boldsymbol{0}, \boldsymbol{I}_{m}).$



>[!info]
>We can heuristically think of the stochastic equation above as 
>$$
>dX_{t} = b(X_{t}, t)\,dt + A(X_{t}, t)\,\left( dt \right)^{1 / 2}
>$$ 
>Thus **symbolically**
>$$
>\frac{dX_{t}}{dt} = b(X_{t}, t) + A(X_{t}, t)\,\frac{dW_{t}}{dt} := b(X_{t}, t) + A(X_{t}, t)\,\xi_{t} 
>$$
>where $\xi_{t}$ represents the **white noise**. Note that  $\frac{d}{dt}W_{t}$ *does not exists almost everywhere*.
>
>$$A(X_{t}, t)\,\xi_{t}$$ is called **multiplicative noise**.

>[!info]
>In simulation, we can replace $dt$ by $\Delta t$ so that 
>$$
>X(t + \Delta t) = X(t) +  b(X(t), t)\,\Delta t + A(X(t), t)\,\sqrt{ \Delta t}\,\xi_{t}
>$$
>where $\xi_{t}$ is i.i.d. Normal distributed.


## Example

>[!example]
>Let $n = m = 1$. Consider the following **linear stochastic differential equation**:
>$$
>\left\{ 
>\begin{align*}
>dX(t) &= g_{t}\,X(t)\,dW\\
>X(0)&= 1
>\end{align*}
>\right.
>$$
>where $g: [0,T] \to \mathbb{R}$ is a **continuous function** not a random variable.
>
>The solution is
>$$
>X_{t} := \exp\left( - \frac{1}{2} \int_{0}^{t}g^2\,ds + \int_{0}^{t}g\,dW  \right)
>$$
>This solution is **unique**.

- [[Linear Stochastic Differential Equation]]
- [[Existence and Uniqueness of Solution for Stochastic Differential Equation]]

>[!info]
>To verify this, we see let $u(x) = \exp\left(x\right)$ so $u_{x}= u$ and $u_{xx} = u$ and 
>$$
>\begin{align*}
>Y_{t} &:= - \frac{1}{2} \int_{0}^{t}g^2\,ds + \int_{0}^{t}g\,dW   \\
> \implies dY_{t} &= -\frac{1}{2} g^2\,dt + g\,dW 
>\end{align*}
>$$
>so that $X_{t} := u\left( Y_{t} \right)$
>$$
>\begin{align*}
>dX_{t} = du\left( Y_{t} \right) &= u_{x}\,dY_{t} + \frac{1}{2} u_{xx}\,dY_{t}\,dY_{t}\\
>&= u\left( Y_{t} \right)\,\left( -\frac{1}{2} g^2\,dt + g\,dW  \right) + \frac{1}{2}u\left( Y_{t} \right)\,\left( -\frac{1}{2} g^2\,dt + g\,dW  \right)^2\\
>&= - u\left( Y_{t} \right)\,\frac{1}{2} g^2\,dt + u\left( Y_{t} \right)\,g\,dW + \frac{1}{2}u\left( Y_{t} \right)\,\left(\left( - \frac{1}{2} g^2 \right)^2\,(dt)^2 -  g^3\,dt\,dW + g^2 (dW)^2  \right)\\
>&= - X_{t}\,\frac{1}{2} g^2\,dt +  g\,X_{t}\,dW + \frac{1}{2}X_{t}g^2\,dt\\
>&= g\,X_{t}\,dW.
>\end{align*}
>$$

- [[Itô Chain Rule and Itô Formula]]

>[!example]
>Let $n = m = 1$. Consider the following **linear stochastic differential equation**:
>$$
>\left\{ 
>\begin{align*}
>dX(t) &= f_{t}\,X(t)\,dt + g_{t}\,X(t)\,dW\\
>X(0)&= 1
>\end{align*}
>\right.
>$$
>where both $f, g: [0,T] \to \mathbb{R}$ are a **continuous function** not a random variable.
>
>The solution is
>$$
>X_{t} := \exp\left(  \int_{0}^{t}\left(f - \frac{1}{2}g^2 \right)\,ds + \int_{0}^{t}g\,dW  \right)
>$$
>This solution is **unique**.

- [[Linear Stochastic Differential Equation]]
- [[Existence and Uniqueness of Solution for Stochastic Differential Equation]]

>[!info]
>Compare with normal O.D.E.
>$$
>\left\{ 
>\begin{align*}
>dX(t) &= f_{t}\,X_{t}\,dt\\
>X(0)&= 1
>\end{align*}
>\right.
>$$
>which has unique solution
>$$
>X_{t} := \exp\left(  \int_{0}^{t}f\,ds  \right)
>$$

- [[Langevin Equation]]
- [[Ornstein–Uhlenbeck Process]]

## Generator of Stochastic Differential Equation

- [[Fokker–Planck and Kolmogorov Forward-Backward Equation]]



-----------
##  Recommended Notes and References

- [[Stochastic Differential]]
- [[Itô Stochastic Integration]]
- [[Itô Stochastic Integration of Step Process]]
- [[Progressively Measurable Stochastic Process]]
- [[Brownian Motion Wiener Process]]


- [[Filtration]]
- [[sigma Algebra Generated by Measurable Functions]]

- [[Introduction to Stochastic Differential Equations by Evans]]
- [[Introduction to Stochastic Calculus by Klebaner]]
- [[Deep Learning Foundations and Concepts by Bishop]] pp 598
- [[Probabilistic Machine Learning Advanced Topics by Murphy]] pp 708, 867, 997