---
tags:
  - concept
  - information_retrieval/retrieval_augmentation
  - deep_learning/large_language_models
  - natural_language_processing/large_language_models
keywords: 
topics: 
name: 
date of note: 2024-10-21
---

## Concept Definition

>[!important]
>**Name**: 



- [[Large Language Model and Pretrained Language Models]]
- [[Generative Pre-trained Transformer or GPT]]
- [[Bidirectional Encoder Representation from Transformer or BERT]]


## Explanation


- [[Question Answering Problem]]


-----------
##  Recommended Notes and References


- [[Attention Mechanism in Neural Network]]
- [[Transformer Network]]
- [[Foundational Models for Transfer Learning]]

- [[Information Retrieval]]


- [[Speech and Language Processing by Jurafsky]] pp 302
- [[lewisRetrievalAugmentedGenerationKnowledgeIntensive2020]] Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Kiela, D. (2020). Retrieval-augmented generation for knowledge-intensive nlp tasks. _Advances in Neural Information Processing Systems_, _33_, 9459-9474.
- Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., ... & Wang, H. (2023). Retrieval-augmented generation for large language models: A survey. _arXiv preprint arXiv:2312.10997_.
- Zhu, Y., Yuan, H., Wang, S., Liu, J., Liu, W., Deng, C., ... & Wen, J. R. (2023). Large language models for information retrieval: A survey. _arXiv preprint arXiv:2308.07107_.
