---
tags:
  - concept
  - statistics/monte_carlo_simulation
keywords:
  - metropolis_hastings_algorithm
  - markov_chain_monte_carlo
topics:
  - statistics/monte_carlo
name: Metropolis-Hastings Algorithm
date of note: 2024-07-04
---

## Concept Definition

>[!important]
>**Name**: Metropolis-Hastings Algorithm

![[Gibbs measure#^bfb840]]

### Metropolis Algorithm

![[Markov Transition Kernel and Transition Function#^8dc85c]]


>[!important]
>A **proposal function** $K: \mathcal{X}\times \mathcal{X} \to \mathbb{R}_{+}$ is defined by a *conditional probability density function*. That is, 
>- For every $x\in \mathcal{X}$, $K(x, \cdot)$ is a *probability density function*.
>- For every $y\in \mathcal{X}$, $K(\cdot, y)$ is a *measurable function*.
>  
>In other word, $$K(x, y) = p(y | x).$$  

- [[Conditional Probability]]


>[!important] Definition
>Consider the problem of sampling from a Gibbs distribution
>$$
>\pi(x) = \frac{1}{Z}\exp \left( - E(x) \right)
>$$
>where the partition function $$Z = \int\exp \left( - E(x) \right) dx.$$
>
>The **Metropolis Algorithm** is described as below:
>- *Initialize* configuration $X_{0}$
>- For $t=1 \,{,}\ldots{,}\,$
>	- **Propose** a random *unbiased* "perturbation" of $X_{t}$ as $Y$
>		- $Y$ is generated by a **symmetric proposal function** $K(X_{t}, \cdot)$ given $X_{t}$, i.e. $$Y \sim K(X_{t},\cdot)$$
>	- Compute the **difference** in **energy**  $$\Delta E := E(Y) - E(X_{t})$$
>	- Generate a **uniform** random variable $U\in \mathcal{U}[0,1]$.
>		- **Accept** $X_{t+1} =Y'$ if $$U \le \frac{\pi(Y)}{\pi(X_{t})} := \exp \left( - \Delta E \right);$$
>		- **Otherwise** accept $X_{t+1} = X_{t}$

- [[Gibbs Distribution]]
- [[Markov Transition Kernel and Transition Function]]
- [[Detailed Balance Equation]]
- [[Accept-Reject Sampling]]

### Metropolis-Hastings Algorithm

>[!important] Definition
>The **Metropolis-Hastings (MH) Algorithm** is described as below:
>- *Initialize* configuration $X_{0}$
>- For $t=1 \,{,}\ldots{,}\,$
>	- **Generate** a random sample $Y$ given $X_{t}$ according to **proposal function** $K(X_{t}, \cdot)$, i.e. $$Y \sim K(X_{t},\cdot)$$
>	- Compute the **Hastings ratio**  $$r(X_{t}, Y) := \frac{\pi(Y)\,K(Y, X_{t})}{\pi(X_{t})\,K(X_{t}\,, Y)}$$
>	- **Metropolis Rejection**: Generate a **uniform** random variable $U\in \mathcal{U}[0,1]$.
>		- **Accept** $X_{t+1} = X'$ if $$U \le \min\{1, \; r(X_{t}, Y)\};$$
>		- **Otherwise** accept $X_{t+1} = X_{t}$

## Explanation

>[!info]
>If the proposal function is **symmetric**, i.e. $$K(x, y) = K(y, x),$$ then the *Metropolis-Hastings Algorithm* is equivalent to the *Metropolis Algorithm.*
>
>$$
>r(X_{t}, Y) = \frac{\pi(Y)K(Y, X_{t})}{\pi(X_{t})K(X_{t}, Y)} =  \frac{\pi(Y)K(X_{t}, Y)}{\pi(X_{t})K(X_{t}, Y)}   =  \frac{\pi(Y)}{\pi(X_{t})} 
>$$

>[!info]
>In [[Hamiltonian Monte Carlo]], the proposal function $K(x, y)$ is defined by a **system of differential equations**.



## Reversible Chain

- [[Time-Reversible Markov Chain]]


## Gibbs Sampling

- [[Gibbs Sampling]]



-----------
##  Recommended Notes and References


- [[Markov Chain and Markov Process]]





- [[All of Statistics A Concise Course by Wasserman]] pp 411
- [[Monte Carlo Statistical Methods by Robert]]
- [[Monte Carlo Strategies in Scientific Computing by Liu]]

- [[Probabilistic Machine Learning Advanced Topics by Murphy]] pp 477 - 537
- [[Deep Learning by Goodfellow]]
- [[Deep Learning Foundations and Concepts by Bishop]] pp 429

- [[Probabilistic Graphical Models by Koller]] pp 516

- Wikipedia [Metropolis-Hastings_algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)