---
tags:
  - entry_point
  - concept
  - math/information_theory
  - statistics/concentration_inequality
  - statistics/estimation
keywords: 
topics:
  - information_theory
name: 
date of note: 2024-06-01
---

## List of Concepts

### Information Measure

- [[Shannon Entropy]]
- [[Kullback-Leibler Divergence]]
- [[Conditional Shannon Entropy]]
- [[Chain Rule of Shannon Entropy]]
- [[Conditional Kullback-Leibler Divegence]]
- [[Chain Rule of Kullback-Leibler Divergence]]


- [[Entropy Functional]]
- [[Phi Entropy Functional]]

- [[Kullback-Leibler Divergence for Exponential Family]]

### Optimal Transport

- [[Concepts and Theorems of Optimal Transport]]

### Inequalities

- [[Jensen Inequality]]
- [[Gibbs Inequality]]
- [[Data-Processing Inequality]]
- [[Han Inequality]]
- [[Variational Formula for Kullback-Leibler Divergence]]
- [[Variational Formula for f-Divergence]]
- [[Variational Formula for Entropy Functional]]

- [[Sub-Additivity of Entropy Functional and Tensorization]]
- [[Sub-Additivity of Phi Entropy Functional]]

- [[Pinsker Inequality]]
- [[Transportation Cost Inequality]]

### Error Correcting Code

- [[Error Correcting Code]]
- [[Packing Number of Metric Space]]
- [[Covering Number of Metric Space]]
- [[Metric Entropy of Metric Space]]


### Compression Theory

- [[Prefix-Free String]]
- [[Occam Razor]]
- [[Minimum Description Length]]
- [[Kraft Inequality]]
- [[Huffman Coding]]

### Communication Theory



### Information Geometry

- [[Information Projection and Moment Projection]]
- [[Maximum Likelihood Estimation via KL Divergence]]
- [[Maximum Entropy Learning]]
- [[Divergence Function on Manifold]]

### Information Divergences on Statistical Manifold

- [[Divergence Function on Manifold]]
- [[Kullback-Leibler Divergence]]
- [[f-Divergence]]
- [[alpha-Divergence]]
- [[Renyi Divergence and Renyi Entropy]]
- [[Hellinger Distance between Distributions]]
- [[Jensen-Shannon Divergence]]
- [[Chi-squared Divergence]]
- [[Total Variation between Measures]]

![[integral_prob_f_diverg.png]]

### Integral Probability Metric and Wasserstein Distance

- [[Integral Probability Metric between Probability Measures]]
- [[Maximum Mean Discrepancy between Probability Measures via RKHS]]
- [[Wasserstein Distance]]




## Explanation





-----------
##  Recommended Notes and References


- [[Elements of Information Theory by Cover]]

- [[Information Inequalities]]
- [[Concepts and Theorems of Optimal Transport]]
- [[Comparison of Information Divergence and Integral Probability Metrics]]


- [[High Dimensional Probability An Introduction by Vershynin]]
- [[High Dimensional Statistics A Non-Asymptotic Viewpoint by Wainwright]]
- [[Concentration Inequalities by Boucheron]]
- [[Mathematical Foundations of Infinite Dimensional Statistical Models by Gine]]

- [[Probabilistic Machine Learning Advanced Topics by Murphy]]