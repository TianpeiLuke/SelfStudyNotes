---
tags:
  - entry_point
  - concept
  - machine_learning/models
  - machine_learning/theory
  - machine_learning/algorithms
  - online_learning/algorithms
keywords: 
topics: 
name: 
date of note: 2024-07-14
---

## Concept Definition

### Stochastic Process, Markov Process,  Martingale

- [[Concepts and Theorems for Stochastic Process]]
- [[Concepts and Theorems for Markov Process]]
- [[Concepts and Theorems for Gaussian Process]]
- [[Concepts and Theorems for Martingale]]

- [[Stochastic Process]]
- [[Markov Transition Kernel and Transition Function]]
- [[Martingale]]
- [[Martingale Differences]]

- [[Stopping Time of Filtration]]
- [[Doob Martingale Convergence Theorem]]
- [[Doob Optional Sampling Theorem]]


### Concentration Inequality 

- [[Basic Inequalities and Cramér–Chernoff Method]]
- [[Martingale Based Inequalities]]

- [[Hoeffding Inequality]]
- [[Bernstein Inequality]]
- [[Hoeffding Inequality]]
- [[Bernstein Inequality]]
- [[Bounded Difference Inequality]]
- [[Doob Maximal Inequality]]


### Convex Optimization Algorithm

- [[Stochastic Gradient Descent Algorithm]]
- [[Iterative Descent]]
- [[Approximation Method for Optimization]]
- [[Proximal Algorithm]]
- [[Dual Proximal Algorithm]]
- [[Augmented Lagrangian Algorithm]]
- [[Alternating Direction Method of Multipliers Algorithm]]


### Prediction with Expert Advice

- [[Prediction with Expert Advice]]
- [[Regret for Online Learning]]
- [[No-Regret Learning]]
- [[Weighted Majority Algorithm for Binary Loss]]
- [[Potential Function for Weighted Average Forecast]]
- [[Weighted Average Forecast via Potential]]
- [[Exponential Weights Algorithm for Convex Loss]]
- [[Regret Analysis for Exponential Weights Algorithm]]
- [[Exponential Weights Algorithm as Mirror Descent]]
- [[Exp-Concave Function]]

### Online Learnability

- [[Online Learnability and Realizabililty Assumption]]
- [[Regret for Online Learning]]
- [[Simple Online Learning Algorithms under Realizability Assumption]]
- [[Shattered Tree by Hypothesis Class]]

### Online Convex Optimization Algorithms

- [[Online Convex Optimization]]
- [[Incremental Algorithm]]
- [[Incremental Gradient Algorithm]]
- [[Incremental Aggregated Gradient Algorithm]]
- [[Online Gradient Decent Algorithm]]

- [[Follow-The-Leader Algorithm]]
- [[Follow-The-Regularized-Leader Algorithm]]
- [[Mirror Descent Algorithm]]
- [[Online Mirror Descent Algorithm]]


### Online Classification

- [[Perceptron Algorithm]]


### Bandit Problem

- [[Stochastic Bandit Problem]]
- [[Explore-Then-Commit Bandit Algorithm]]
- [[epsilon-Greedy Algorithm]]

- [[Principle of Optimism under Uncertainty]]
- [[Upper Confidence Bound Algorithm]]
- [[Upper Confidence Bound Algorithm Asymptotic Optimality]]
- [[Upper Confidence Bound Algorithm Minmax Optimality]]
- [[KL-Upper Confidence Bound Algorithm]]
- [[Bandit Gradient Algorithm]]

- [[Multi-Armed Adversarial Bandit]]
- [[Exploration and Exploitation Tradeoff]]
- [[EXP3 or Exponential Weights Algorithm for Exploration and Exploitation]]


- [[Contextual Bandit Problem]]
- [[Linear Contextual Bandit Problem]]


### Approximate Dynamic Programming

- [[Models and Algorithms for Reinforcement Learning]]


### Boosting

- [[Online Learning Perspective for AdaBoost]]
- [[Concepts and Theorems in Boosting and Ensemble Learning]]



## Explanation





-----------
##  Recommended Notes and References


- [[Prediction Learning and Games by Cesa-Bianchi]]
- [[Bandit Algorithms by Lattimore]]
- [[Online Learning and Online Convex Optimization by Shalev-Shwartz]]
- [[Introduction to Online Convex Optimization by Hazan]]


- [[Foundations of Machine Learning by Mohri]]
- [[Understanding Machine Learning by Shalev-Shwartz]]
- [[Boosting Foundations and Algorithms by Schapire]]
- [[Elements of Statistical Learning by Hastie]]
- [[Convex Optimization Algorithms by Bertsekas]]