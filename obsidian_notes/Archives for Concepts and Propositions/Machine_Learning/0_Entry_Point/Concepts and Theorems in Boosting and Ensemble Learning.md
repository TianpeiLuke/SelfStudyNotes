---
tags:
  - entry_point
  - concept
  - machine_learning/theory
  - machine_learning/models
  - statistics/concentration_inequality
  - math/stochastic_process
  - machine_learning/boosting
keywords: 
topics:
  - machine_learning_theory
  - machine_learning_models
  - concentration_inequality
  - stochastic_process
  - boosting
name: 
date of note: 2024-07-28
---

## List of Concepts

### Empirical Process and Learning Theory

- [[Concepts and Inequalities for Empirical Process]]
- [[Concepts and Theorems in Statistical Learning Theory]]
- [[Regression Problem]]

### Empirical Risk Minimization

- [[Empirical Risk Minimization]]
- [[Realizability Assumption for Empirical Risk Minimization]]
- [[PAC Learnable and Agnostic PAC Learnable]]
- [[Rademacher Complexity Bound for Binary Classification]]
- [[Rademacher Complexity of a Convex Hull of Function Class]]

### AdaBoost Algorithm

- [[Ensemble Learning]]
- [[AdaBoost Algorithm]]
- [[Training Error Bound for AdaBoost]]
- [[Partition Function for AdaBoost]]

- [[AdaBoost Algorithm for Multiclass Classification]]

### Weak and Strong PAC Learning for Boosting

- [[Generalization Error Bound for AdaBoost Finite Case]]
- [[Generalization Error Bound for AdaBoost VC Dimension]]

- [[Rademacher Complexity of a Convex Hull of Function Class]]
- [[Generalization Error Bound for AdaBoost Rademacher Complexity]]

- [[Weak PAC Learnablity]]
- [[Empirical Weak Learning Assumption]]
- [[Equivalence of Strong and Weak Learnability]]

### Margin-based Theory

- [[Margin as a Measure of Classification Confidence]]
- [[Margin-based Bound for AdaBoost]]

### Greedy Optimization for Boosting

- [[Partition Function for AdaBoost]]
- [[Forward Stagewise Additive Modeling]]
- [[Exponential Loss Minimization for AdaBoost]]


### Maximum Entropy Learning for Boosting

- [[Iterative Maximum Entropy Learning for AdaBoost]]
- [[Dual Optimization Problem for AdaBoost]]

### Functional Gradient Descent Perspective

- [[Functional Gradient Descent]]
- [[Gradient Boosting Algorithm]]
- [[Gradient Boosting Trees]]
- [[Iterative Maximum Entropy Learning for Gradient Boosting]]
- [[XGBoost and LightGBM]]

### Game Theory and Online Learning

- [[Models and Algorithms for Online Learning]]
- [[Exponential Weights Algorithm for Convex Loss]]
- [[Exponential Weights Algorithm as Mirror Descent]]
- [[Sequential Game Perspective for AdaBoost]]


### Ensemble Learning and Generalization of Boosting

- [[Ensemble Learning]]
- [[Forward Stagewise Additive Modeling]]

### Bootstrap

- [[Bootstrap Method]]




## Explanation





-----------
##  Recommended Notes and References

- [[Foundations of Machine Learning by Mohri]]
- [[Understanding Machine Learning by Shalev-Shwartz]]
- [[Boosting Foundations and Algorithms by Schapire]]
- [[Elements of Statistical Learning by Hastie]]



- [[Mathematical Foundations of Infinite Dimensional Statistical Models by Gine]]
- [[High Dimensional Statistics A Non-Asymptotic Viewpoint by Wainwright]]