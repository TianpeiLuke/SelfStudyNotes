---
tags:
  - entry_point
  - concept
  - machine_learning/theory
  - machine_learning/models
  - machine_learning/metrics
  - statistics/concentration_inequality
  - math/stochastic_process
keywords: 
topics:
  - machine_learning_theory
  - machine_learning_models
  - concentration_inequality
  - stochastic_process
name: 
date of note: 2024-06-01
---

## List of Concepts

### Empirical Process

- [[Concepts and Inequalities for Empirical Process]]

- [[Empirical Process and Empirical Measure]]
- [[Glivenko-Cantelli Theorem]]
- [[Glivenko-Cantelli Class]]

- [[Symmetrized Empirical Process]]
- [[Talagrand Contraction Principle]]
- [[Rademacher Complexity]]
- [[Uniform Bound via Rademacher Complexity]]
- [[Rademacher Complexity Lower Bound for Suprema of Empirical Process]]
- [[Rademacher Complexity Upper Bound for Suprema of Empirical Process]]

- [[Restriction of Function Class to Data]]
- [[Shattering of Data by Function Class]]
- [[VC Dimension]]
- [[Growth Function of Function Class]]
- [[Sauer-Shelah Lemma for VC Dimension]]

- [[Supremum of Empirical Process indexed by VC Class]]
- [[Metric Entropy Bound of VC Class]]

### Empirical Risk Minimization

- [[Empirical Risk Minimization]]
- [[Statistical Learning via Statistical Decision Theory]]
- [[Realizability Assumption for Empirical Risk Minimization]]
- [[PAC Learnable and Agnostic PAC Learnable]]
- [[Generalization Error Bound for Binary Classification Finite Case]]
- [[Generalization Error Bound for Binary Classification VC Dimension]]
- [[Rademacher Complexity]]
- [[Rademacher Complexity Bound for Binary Classification]]


### Convex Learning Problem

- [[Convex Function]]
- [[Concentration of Separately Convex Lipschitz Functions]]
- [[Concentration of Quasi-Convex Lipschitz Functions]]



### Regularization and Structural Risk Minimization

- [[Bias-Variance Tradeoff]]
- [[Non-Uniform Learning]]
- [[Structural Risk Minimization]]
- [[Regularized Loss Minimization]]
- [[Tikhonov Regularization in Optimization and Learning]]

- [[PAC-Bayes Learnable]]


### K Nearest Neighbor



### Boosting and Ensemble Learning

- [[Concepts and Theorems in Boosting and Ensemble Learning]]
- [[AdaBoost Algorithm]]

- [[Generalization Error Bound for AdaBoost Finite Case]]
- [[Generalization Error Bound for AdaBoost VC Dimension]]
- [[Weak PAC Learnablity]]
- [[Empirical Weak Learning Assumption]]
- [[Equivalence of Strong and Weak Learnability]]

- [[Rademacher Complexity of a Convex Hull of Function Class]]
- [[Generalization Error Bound for AdaBoost Rademacher Complexity]]

### Reproducing Kernel Hilbert Space

- [[Evaluation Functional]]
- [[Reproducing Kernel Hilbert Space]]
- [[Representation of Evaluational Functional in RKHS]]
- [[Reproducing Kernel of RKHS]]
- [[RKHS of Gaussian Random Function]]
- [[Covariance Function of Gaussian Process]]


### Margin-based Generalization Bound

- [[Margin as a Measure of Classification Confidence]]


### Probabilistic Graphical Model

- [[Models and Algorithms for Probabilistic Graphical Models]]
- [[Probabilistic Graphical Models]]

### Gaussian Process

- [[Concepts and Theorems for Gaussian Process]]

### Deep Learning

- [[Models and Algorithms for Deep Learning]]

### Reinforcement Learning

- [[Markov Decision Process]]
- [[Models and Algorithms for Reinforcement Learning]]

### Online Learning

- [[Models and Algorithms for Online Learning]]




## Explanation





-----------
##  Recommended Notes and References


- [[Foundations of Machine Learning by Mohri]]
- [[Understanding Machine Learning by Shalev-Shwartz]]
- [[Boosting Foundations and Algorithms by Schapire]]
- [[Elements of Statistical Learning by Hastie]]


- [[Probabilistic Graphical Models by Koller]]
- [[Probabilistic Machine Learning Advanced Topics by Murphy]]



- [[Concentration Inequalities by Boucheron]]
- [[Mathematical Foundations of Infinite Dimensional Statistical Models by Gine]]
- [[High Dimensional Statistics A Non-Asymptotic Viewpoint by Wainwright]]
- [[High Dimensional Probability An Introduction by Vershynin]]