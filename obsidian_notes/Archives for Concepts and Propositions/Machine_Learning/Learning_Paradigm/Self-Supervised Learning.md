---
tags:
  - concept
  - machine_learning/strategy
keywords: 
topics:
  - machine_learning_strategy
name: 
date of note: 2024-07-07
---

## Concept Definition

>[!important]
>**Name**: 






## Explanation



## Self-Supervised Training of Word Embedding

![[word2vec_cont_bog_skipgram.png]]

- [[Word2Vec Algorithm for Static Word Embedding]]
- [[Continuous-Bag-of-Words Algorithm for Word Embedding]]
- [[Skip-Gram Algorithm with Negative Sampling for Word Embedding]]

## Self-Supervised Training of RNN

![[self_train_rnn.png]]

- [[Recurrent Neural Network]]
- [[Long-Short Term Memory Network]]
- [[Gated Recurrent Units in Neural Network]]


## Self-Supervised Pre-Training of Transformer Networks

- [[Large Language Model and Pretrained Language Models]]
### Encoder-Only Architecture

![[masked_language_model_training.png]]

- [[Masked Language Modeling as Language Model Training Task]]

![[next_sentence_prediction_loss.png]]

- [[Next Sentence Prediction as Language Model Training Task]]

### Decoder-Only Architecture

![[self_supervised_training_llm.png]]

- [[Self-Supervised Training of Large Language Model and Teacher Forcing]]



-----------
##  Recommended Notes and References


- [[Deep Learning Foundations and Concepts by Bishop]] pp 5, 375
- [[Probabilistic Machine Learning Advanced Topics by Murphy]]
- [[Deep Learning by Goodfellow]] pp 372 - 373
- [[Speech and Language Processing by Jurafsky]] pp 155, 163, 210 - 211