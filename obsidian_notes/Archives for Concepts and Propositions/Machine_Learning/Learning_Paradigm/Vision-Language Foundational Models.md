---
tags:
  - concept
  - large_language_models
  - vision_language_models
  - deep_learning/large_language_models
  - foundational_models
keywords:
  - vision_language_models
topics:
  - multi-modal_learning
  - machine_learning_paradigm
  - deep_learning/large_language_models
name: Vision-Language Foundational Models
date of note: 2025-05-05
---

## Concept Definition

>[!important]
>**Name**: Vision-Language Foundational Models


- [[Foundational Models for Transfer Learning]]

## Explanation


- [[Contrastive Language Image Pre-training or CLIP]]




-----------
##  Recommended Notes and References


- [[Vision Transformer or ViT]]
- [[Large Language Model and Pretrained Language Models]]
- [[radfordLearningTransferableVisual2021]]  Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., & Sutskever, I. (2021). Learning Transferable Visual Models From Natural Language Supervision. _Proceedings of the 38th International Conference on Machine Learning_, 8748â€“8763. 
- Zhou, K., Yang, J., Loy, C. C., &; Liu, Z. (2022). Learning to Prompt for Vision-Language Models. *International Journal of Computer Vision*, *130* (9), 2337 2348. https://doi.org/10.1007/s11263-022-01653-1
- Gan, Z., Li, L., Li, C., Wang, L., Liu, Z., &amp; Gao, J. (2022). Vision-Language Pre-Training: Basics, Recent Advances, and Future Trends. *Foundations and Trends in Computer Graphics and Vision*, *14* (3-4), 163-352. https://doi.org/10.1561/0600000105

