---
tags:
  - concept
  - deep_learning/models
  - machine_learning/strategy
  - multi-task_learning
keywords:
  - multi-task_learning
topics:
  - machine_learning_strategy
name: Muti-Task Learning
date of note: 2024-11-29
---

## Concept Definition

>[!important]
>**Name**: Muti-Task Learning

>[!important] Definition
>**Multi-Task Learning (MTL)** is a machine learning framework where a single model is trained to perform *multiple related tasks simultaneously*, leveraging *shared representations* to improve generalization across all tasks. 
>- By learning tasks together rather than independently, the model can *exploit commonalities and differences between tasks*, often leading to better performance, faster convergence, and reduced overfitting, especially when some tasks have *limited labeled data*.
>- MTL typically involves *shared lower layers* that extract general features, with task-specific heads or layers that specialize for individual outputs.



## Explanation


- [[Continued Pre-training of Large Language Models]]
- [[Self-Supervised Training of Large Language Model and Teacher Forcing]]

## Meta Learning

- [[Meta Learning]]



-----------
##  Recommended Notes and References


- [[Transfer Learning]]
- [[Multi-Modal Learning]]
- [[Multi-view Learning]]
- [[Large Language Model and Pretrained Language Models]]


- [[Deep Learning by Goodfellow]] pp 237, 528
- [[Deep Learning Foundations and Concepts by Bishop]] pp 190
- [[Probabilistic Machine Learning Advanced Topics by Murphy]] pp 743
- [[Speech and Language Processing by Jurafsky]] pp 214
- [[Foundations of Computer Vision by Torralba]] pp 543