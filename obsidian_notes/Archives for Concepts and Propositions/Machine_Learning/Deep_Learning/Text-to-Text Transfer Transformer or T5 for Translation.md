---
tags:
  - concept
  - deep_learning/architecture
  - deep_learning/models
  - deep_learning/large_language_models
  - natural_language_processing/large_language_models
keywords:
  - t5_transformer
  - machine_translation_models
topics:
  - deep_learning/models
  - natural_language_processing/large_language_models
name: Text-to-Text Transfer Transformer or T5 for Translation
date of note: 2024-10-21
---

## Concept Definition

>[!important]
>**Name**: Text-to-Text Transfer Transformer or T5 for Translation


### Encoder-Decoder Transformer Architecture




![[encoder_decoder_transformer.png]]

- [[Encoder-Decoder Sequence-to-Sequence Architecture]]


### Tokenization via Unigram 

![[Unigram Tokenization#^5a3115]]

- [[Unigram Tokenization]]



### Text Generation via Sampling

- [[Decoding and Sampling from Large Language Models]]
- [[Top-k Sampling for Large Language Model Generation]]
- [[Top-p Sampling or Nucleus Sampling for Large Language Model Generation]]
- [[Temperature Sampling for Large Language Model Generation]]
- [[Beam Search for Causal Decoding of Language Model]]

### Self-Supervised Training

- [[Self-Supervised Training of Large Language Model and Teacher Forcing]]

### Instruction Fine Tuning

- [[Supervised Fine-Tuning or Instruction Fine-Tuning of LLM]]

### Human Alignment

- [[Reinforcement Learning with Human Feedbacks or RLHF for LLM]]
- [[Direct Preference Optimization for Alignment in LLM]]



## Explanation





## Dataset in Experiment

### Parallel Corpus

### Sentence Alignment



## Evaluation

- [[Bilingual Evaluation Understudy or BLEU metric for LLM Generation]]



-----------
##  Recommended Notes and References


- [[Attention Mechanism in Neural Network]]
- [[Transformer Network]]
- [[Large Language Model and Pretrained Language Models]]
- [[Encoder-Decoder Sequence-to-Sequence Architecture]]

- [[Generative Pre-trained Transformer or GPT]]
- [[Bidirectional Encoder Representation from Transformer or BERT]]

- [[Bidirectional Recurrent Neural Network]]
- [[Artificial Neural Network and Deep Learning]]

- [[raffelExploringLimitsTransfer2020]]

- [[Speech and Language Processing by Jurafsky]] pp 268 - 278