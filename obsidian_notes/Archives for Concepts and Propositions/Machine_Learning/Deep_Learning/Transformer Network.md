---
tags:
  - concept
  - machine_learning/models
  - deep_learning/generative_models
  - deep_learning/architecture
  - deep_learning/models
keywords:
  - transformer_network
  - attention_network
  - self_attention_network
topics:
  - deep_learning/network_block
  - deep_learning/models
  - deep_learning/generative_models
name: Transformer Network
date of note: 2024-05-12
---

## Concept Definition

>[!important]
>**Name**: Transformer Network

### Transformer Block




![[transformer_block.png]]

- [[Attention Mechanism in Neural Network]]
- [[Multi-Layer Perceptron and Feed-Forward Network]]
- [[Residual Neural Network]]
- [[Layer Normalization]]

### Transformer Network


![[transformer.png]]






## Explanation





-----------
##  Recommended Notes and References



- [[Artificial Neural Network and Deep Learning]]

- [[Probabilistic Machine Learning Advanced Topics by Murphy]] pp 637
- [[Deep Learning Foundations and Concepts by Bishop]] pp 357
- [[vaswaniAttentionAllYou2017]] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, ≈Å., & Polosukhin, I. (2017). Attention is All you Need. _Advances in Neural Information Processing Systems_, _30_. [https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html](https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)