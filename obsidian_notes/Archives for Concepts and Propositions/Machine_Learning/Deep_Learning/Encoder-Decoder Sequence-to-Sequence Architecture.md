---
tags:
  - concept
  - deep_learning/sequential_networks
  - deep_learning/models
keywords:
  - bidirectional_rnn
  - bidirectional
topics:
  - deep_learning/models
name: Encoder-Decoder Sequence-to-Sequence Architecture
date of note: 2024-08-31
---

## Concept Definition

>[!important]
>**Name**: Encoder-Decoder Sequence-to-Sequence Architecture


### RNN

- [[Recurrent Neural Network]]
- [[Gated Recurrent Units in Neural Network]]
- [[Long-Short Term Memory Network]]
- [[Residual Neural Network]]
- [[Bidirectional Recurrent Neural Network]]

### Auto-Encoder

- [[Variational Auto-Encoder]]
- [[Auto-Encoder and Stochastic Auto-Encoder]]


### Diffusion Network

- [[Denoising Diffusion Probabilistic Models and Diffusion Network]]
- [[Continuous-Time Diffusion Network via Stochastic Differential Equations]]


### Transformer Network

- [[Transformer Network]]
- [[Large Language Model and Pretrained Language Models]]
- [[Bidirectional Encoder Representation from Transformer or BERT]]
- [[Generative Pre-trained Transformer or GPT]]




## Explanation


- [[Linear Dynamic System]]



-----------
##  Recommended Notes and References






- [[Deep Learning by Goodfellow]] pp 383 - 384
- [[Deep Learning Foundations and Concepts by Bishop]]
- [[Probabilistic Machine Learning Advanced Topics by Murphy]] 