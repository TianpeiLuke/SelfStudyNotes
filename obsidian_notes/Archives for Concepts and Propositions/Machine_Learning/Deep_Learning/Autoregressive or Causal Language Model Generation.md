---
tags:
  - concept
  - deep_learning/generative_models
  - natural_language_processing/large_language_models
  - deep_learning/large_language_models
keywords: 
topics: 
name: 
date of note: 2024-11-24
---

## Concept Definition

>[!important]
>**Name**: Autoregressive or Causal Language Model Generation


- [[Autoregressive Models]]
- [[Large Language Model and Pretrained Language Models]]

- [[Causal Convolutional Neural Network]]

### Top-$k$ Sampling


- [[Top-k Sampling for Large Language Model Generation]]
- [[Greedy Decoding for Language Model]]
- [[Beam Search as Greedy Decoding]]

### Top-$p$ Sampling or Nucleus Sampling


- [[Top-p Sampling or Nucleus Sampling for Large Language Model Generation]]

### Temperature Sampling

- [[Temperature Sampling for Large Language Model Generation]]



## Explanation



- [[Generative Pre-trained Transformer or GPT]]
- [[Encoder-Decoder Sequence-to-Sequence Architecture]]






-----------
##  Recommended Notes and References

- [[Transformer Network]]
- [[Artificial Neural Network and Deep Learning]]

- [[Speech and Language Processing by Jurafsky]] pp 207 - 208
- [[Deep Learning Foundations and Concepts by Bishop]] pp 386 - 387
- [[Probabilistic Machine Learning Advanced Topics by Murphy]]