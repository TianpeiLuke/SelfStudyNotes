---
tags:
  - concept
  - natural_language_processing/word_representation
keywords:
  - skip_gram_word_embedding
topics:
  - natural_language_processing/word_representation
name: Skip-Gram Algorithm with Negative Sampling for Word Embedding
date of note: 2024-09-12
---

## Concept Definition

>[!important]
>**Name**: Skip-Gram Algorithm with Negative Sampling for Word Embedding

### Learning Word Embedding with Classification


- [[Word2Vec Algorithm for Static Word Embedding]]



![[skipgram_embedding.png]]


### Learning Skip-Gram Embedding with Negative Sampling





## Explanation


![[word2vec_cont_bog_skipgram.png]]

- [[Contiuous-Bag-of-Words Algorithm for Word Embedding]]




-----------
##  Recommended Notes and References


- [[n-Gram Model and Language Model]]
- [[Word Embedding]]
- [[n-Gram Model and Language Model]]
- [[Cosine Similarity and Cosine Distance]]


- [[Probabilistic Latent Semantic Analysis]]
- [[Latent Dirichlet Allocation]]

- [[Vector Space over a Field]]

- [[Speech and Language Processing by Jurafsky]] pp 116 - 122
- Wikipedia [Vector_space_model](https://en.wikipedia.org/wiki/Vector_space_model)