---
tags:
  - concept
  - natural_language_processing/word_representation
keywords: 
topics: 
name: 
date of note: 2024-09-12
---

## Concept Definition

>[!important]
>**Name**: 







## Explanation

![[word2vec_cont_bog_skipgram.png]]

- [[Skip-Gram Algorithm with Negative Sampling for Word Embedding]]



-----------
##  Recommended Notes and References



- [[Bag-of-Word Model for Document Representation]]
- [[Word Embedding]]
- [[n-Gram Model and Language Model]]
- [[Cosine Similarity and Cosine Distance]]


- [[Probabilistic Latent Semantic Analysis]]
- [[Latent Dirichlet Allocation]]

- [[Vector Space over a Field]]

- Wikipedia [Word2vec](https://en.wikipedia.org/wiki/Word2vec)
- [[Speech and Language Processing by Jurafsky]] 
- Mikolov, T., Chen, K., Corrado, G.S., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. _International Conference on Learning Representations_.
- Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. _Advances in neural information processing systems_, _26_.