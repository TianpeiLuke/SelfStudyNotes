---
tags:
- '#paper'
aliases: "chenXGBoostScalableTree2016"
year: 2016
name: "XGBoost: A Scalable Tree Boosting System"
authors: "Tianqi Chen, Carlos Guestrin"
publication: ""
type: "conferencePaper"
DOI: "10.1145/2939672.2939785"
date of note: 2024-05-12 
---
# Descriptions

## XGBoost: A Scalable Tree Boosting System 
> [!info] 
> - **Abstract:** Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems. 
> - **Sources**: [online](http://zotero.org/users/13492210/items/Y5VQ8JF7) [local](zotero://select/library/items/Y5VQ8JF7) [pdf](file:////home/lukexie/Documents/Papers/storage/59SZWKF9/Chen%20and%20Guestrin%20-%202016%20-%20XGBoost%20A%20Scalable%20Tree%20Boosting%20System.pdf) 
> - **Bibliography**: Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. _Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_, 785â€“794. [https://doi.org/10.1145/2939672.2939785](https://doi.org/10.1145/2939672.2939785)
> - **Cite Key:** [[@chenXGBoostScalableTree2016]] 
> - **Conclusion**:
> - **Tags:** #large-scale-machine-learning, #XGBoost


>[!note] Highlights:
>
>-
>-
>-



# Questions
## Questions Regarding to This Paper


>[!question] 
>What are the *primary assumptions* behind this paper?



>[!question]
>What are the major *problems of concern* behind this paper? If i had to guess, what does the author seems to be concerned. 




>[!question]
>What are *the main contributions* of the paper?




>[!todo]
>Highlight the main techniques proposed in this paper. Also highlight the performance comparison to state-of-the-art.



## Questions Related to Me


> [!question] 
> Is the problem behind this paper related to problem of mine?



> [!question] 
> What impact does this paper have on me?




----

## Reference and Related Notes