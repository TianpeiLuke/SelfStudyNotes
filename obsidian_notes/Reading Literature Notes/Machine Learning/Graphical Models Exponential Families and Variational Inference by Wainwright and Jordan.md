---
tags:
  - book
  - machine_learning/models
  - math/information_theory
  - optimization/algorithm
aliases:
  - wainwrightGraphicalModelsExponential2008
year: 2008
name: Graphical Models, Exponential Families, and Variational Inference
authors: Martin J. Wainwright, Michael I. Jordan
publication: Foundations and Trends® in Machine Learning
type: journalArticle
DOI: 10.1561/2200000001
date of note: 2024-05-12
---

> [!Cite]  
> Wainwright, M. J., & Jordan, M. I. (2008). Graphical Models, Exponential Families, and Variational Inference. _Foundations and Trends® in Machine Learning_, _1_(1–2), 1–305. [https://doi.org/10.1561/2200000001](https://doi.org/10.1561/2200000001)

>[!Synth]  
>**Contribution**::  
>  
>**Related**::   
>  
  
>[!md]  
> **FirstAuthor**:: Wainwright, Martin J.  
> **Author**:: Jordan, Michael I.  
~  
> **Title**:: Graphical Models, Exponential Families, and Variational Inference  
> **Year**:: 2008  
> **Citekey**:: wainwrightGraphicalModelsExponential2008  
> **itemType**:: journalArticle  
> **Journal**:: *Foundations and Trends® in Machine Learning*  
> **Volume**:: 1  
> **Issue**:: 1–2  
> **Pages**:: 1-305  
> **DOI**:: 10.1561/2200000001  

> [!LINK]  
> 
> [Wainwright and Jordan - 2008 - Graphical Models, Exponential Families, and Variat.pdf](file:///home/lukexie/Documents/Papers/storage/JU8T9BYE/Wainwright%20and%20Jordan%20-%202008%20-%20Graphical%20Models,%20Exponential%20Families,%20and%20Variat.pdf) 
>  

> [!Abstract]  
> The formalism of probabilistic graphical models provides a unifying framework for capturing complex dependencies among random variables, and building large-scale multivariate statistical models. Graphical models have become a focus of research in many statistical, computational and mathematical fields, including bioinformatics, communication theory, statistical physics, combinatorial optimization, signal and image processing, information retrieval and statistical machine learning. Many problems that arise in specific instances — including the key problems of computing marginals and modes of probability distributions — are best studied in the general setting. Working with exponential family representations, and exploiting the conjugate duality between the cumulant function and the entropy for exponential families, we develop general variational representations of the problems of computing likelihoods, marginal probabilities and most probable configurations. We describe how a wide variety of algorithms — among them sum-product, cluster variational methods, expectation-propagation, mean field methods, max-product and linear programming relaxation, as well as conic programming relaxations — can all be understood in terms of exact or approximate forms of these variational representations. The variational approach provides a complementary alternative to Markov chain Monte Carlo as a general source of approximation methods for inference in large-scale statistical models.  


-----
## Reference

- [[Probabilistic Graphical Models by Koller]]
- [[Probabilistic Machine Learning Advanced Topics by Murphy]]