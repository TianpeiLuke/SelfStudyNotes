---
tags:
  - book
aliases:
  - boucheronConcentrationInequalitiesNonasymptotic2013
year: 2014
name: "Concentration Inequalities: A Nonasymptotic Theory of Independence"
authors: Stéphane Boucheron, Gábor Lugosi, Pascal Massart
publication: Oxford University Press
type: book
DOI: ""
date of note: 2024-05-06
---

> [!Cite]  
> Boucheron, S., Lugosi, G., & Massart, P. (2013). _Concentration Inequalities: A Nonasymptotic Theory of Independence_. Oxford University Press. [https://doi.org/10.1093/acprof:oso/9780199535255.001.0001](https://doi.org/10.1093/acprof:oso/9780199535255.001.0001)

  
>[!md]  
> **FirstAuthor**:: Boucheron, Stéphane  
> **Author**:: Lugosi, Gábor  
> **Author**:: Massart, Pascal  
~  
> **Title**:: Concentration Inequalities: A Nonasymptotic Theory of Independence  
> **Year**:: 2013  
> **Citekey**:: boucheronConcentrationInequalitiesNonasymptotic2013  
> **itemType**:: book  
> **Publisher**:: Oxford University Press  
> **ISBN**:: 978-0-19-953525-5  

> [!LINK]  
>  
> [Boucheron et al. - 2013 - Concentration inequalities A nonasymptotic theory.pdf](file:///Users/lukexie/Zotero/storage/EXQIFZKE/Boucheron%20et%20al.%20-%202013%20-%20Concentration%20inequalities%20A%20nonasymptotic%20theory.pdf) 


> [!Abstract]  
 >
>This monograph presents a mathematical theory of concentration inequalities for functions of independent random variables. The basic phenomenon under investigation is that if a function of many independent random variables does not depend too much on any of them then it is concentrated around its expected value. This book offers a host of inequalities to quantify this statement. The authors describe the interplay between the probabilistic structure (independence) and a variety of tools ranging from functional inequalities, transportation arguments, to information theory. Applications to the study of empirical processes, random projections, random matrix theory, and threshold phenomena are presented. The book offers a self-contained introduction to concentration inequalities, including a survey of concentration of sums of independent random variables, variance bounds, the entropy method, and the transportation method. Deep connections with isoperimetric problems are revealed. Special attention is paid to applications to the supremum of empirical processes.  

# Basic Inequalities

- [[Basic Inequalities and Cramér–Chernoff Method]]

# Bounding the Variance



# Basic Information Inequalities

- [[Information Inequalities]]

# Logarithmic Sobolev Inequalities

- [[Entropy Methods and Logarithmic Sobolev Inequalities]]
	- [[Herbst Argument]]
	- [[Logarithmic Sobolev Inequality for Bernoulli Random Variables]]
	- [[Logarithmic Sobolev Inequality for Gaussian Random Variables]]

# Entropy Method

- [[Entropy Methods and Logarithmic Sobolev Inequalities]]

# Concentration and Isoperimetry

- [[Concentration of Measure in Metric Space]]

# Transportation Method

- [[Transportation Method]]

# Influence and Threshold Phenomena





# Isoperimetry on the Hypercube and Gaussian Space



# The Variance of Suprema of Empirical Process




# Suprema of Empirical Process: Exponential Inequalities




# The Expected Value of Suprema of Empirical Processes





# $\Phi$-Entropies

- [[Phi Entropy Functional]]


# Moment Inequalities



  

---
## Reference

- [[High Dimensional Statistics A Non-Asymptotic Viewpoint by Wainwright]]
- [[High Dimensional Probability An Introduction by Vershynin]]
- [[Elements of Information Theory by Cover]]