---
tags:
  - excerpt
  - documentation
  - code_package
  - python
  - package/huggingface
  - transformers
aliases: 
keywords:
  - huggingface/transformers
topics:
  - code/doc
language: python
date of note: 2024-03-25
name: Hugging Face `dataset` package official doc
version: 4.39.1
year: 2024
---
# About Package

>[!quote]
>State-of-the-art Machine Learning forÂ [PyTorch](https://pytorch.org/),Â [TensorFlow](https://www.tensorflow.org/), andÂ [JAX](https://jax.readthedocs.io/en/latest/).
> 
> ðŸ¤— Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as:
> 
> ðŸ“Â **Natural Language Processing**: text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation.  
> ðŸ–¼ï¸Â **Computer Vision**: image classification, object detection, and segmentation.  
> ðŸ—£ï¸Â **Audio**: automatic speech recognition and audio classification.  
> ðŸ™Â **Multimodal**: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.
> 
> ðŸ¤— Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a modelâ€™s life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments.
> -- [link](https://huggingface.co/docs/transformers/index#-transformers)

## Overview 

- [link](https://huggingface.co/docs/datasets/how_to)

> [!quote]
>The documentation is organized into five sections:
> 
> - **GET STARTED**Â provides a quick tour of the library and installation instructions to get up and running.
>     
> - **TUTORIALS**Â are a great place to start if youâ€™re a beginner. This section will help you gain the basic skills you need to start using the library.
>     
> - **HOW-TO GUIDES**Â show you how to achieve a specific goal, like finetuning a pretrained model for language modeling or how to write and share a custom model.
>     
> - **CONCEPTUAL GUIDES**Â offers more discussion and explanation of the underlying concepts and ideas behind models, tasks, and the design philosophy of ðŸ¤— Transformers.
>     
> - **API**Â describes all classes and functions:
>     
>     - **MAIN CLASSES**Â details the most important classes like configuration, model, tokenizer, and pipeline.
>     - **MODELS**Â details the classes and functions related to each model implemented in the library.
>     - **INTERNAL HELPERS**Â details utility classes and functions used internally.






-----------
##  Recommended Notes







----------
##  Citations

**Hugging face** `transformers` package documentation
- Home page [link](https://huggingface.co/docs/transformers/index)
- overview [doc](https://huggingface.co/docs/datasets/how_to)



