\relax 
\citation{schapire2012boosting}
\citation{schapire2012boosting}
\citation{schapire2012boosting}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\textbf  {AdaBoost Algorithm \citep  {schapire2012boosting}}}\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: adaboost}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Boosting Algorithm}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}AdaBoost}{2}}
\citation{cesa2006prediction}
\citation{gabriel2019computational}
\citation{thomas2006elements}
\citation{hastie2009elements}
\citation{hastie2009elements}
\citation{hastie2009elements}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Functional Gradient Descent}{5}}
\newlabel{eqn: functional_gradient_on_samples}{{1}{5}}
\newlabel{eqn: functional_gradient_descent}{{2}{5}}
\citation{hastie2009elements}
\citation{hastie2009elements}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\textbf  {A generic boosting algorithm based on functional gradient descent \citep  {hastie2009elements}}}\relax }}{6}}
\newlabel{fig: grad_boost}{{2}{6}}
\newlabel{def: exp_loss}{{3}{6}}
\newlabel{eqn: adaboost_functional_gradient_on_samples}{{4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Gradient Boost}{6}}
\newlabel{eqn: grad_boost}{{5}{6}}
\newlabel{eqn: grad_boost_regression_task}{{6}{6}}
\citation{schapire2012boosting}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\textbf  {Gradient Boost Tree Algorithm \citep  {hastie2009elements}}}\relax }}{7}}
\newlabel{fig: grad_boost}{{3}{7}}
\citation{mohri2018foundations}
\citation{schapire2012boosting,shalev2014understanding}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretical Guarantee for Boosting}{8}}
\newlabel{expr: gen_err_determin}{{7}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Weak Learner}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Training Error Bounds}{9}}
\newlabel{def: linear_ensemble_class}{{8}{9}}
\citation{schapire2012boosting}
\newlabel{prop: training_error_bound}{{2.1}{10}}
\newlabel{ineqn: boosting_training_error_bound}{{9}{10}}
\newlabel{pf: training_error_bound_1}{{10}{10}}
\citation{shalev2014understanding,mohri2018foundations}
\citation{mohri2018foundations}
\newlabel{pf: partition_fun_train_error}{{11}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Generalization Error Bounds for Finite Hypothesis Class}{11}}
\newlabel{eqn: sauer_lemma}{{12}{11}}
\newlabel{cor: generalization_bound_growth}{{2.3}{11}}
\citation{schapire2012boosting,mohri2018foundations}
\citation{schapire2012boosting,shalev2014understanding}
\citation{schapire2012boosting}
\newlabel{ineqn: generalization_bound_growth_number}{{13}{12}}
\newlabel{ineqn: generalization_bound_growth_number_2}{{14}{12}}
\newlabel{ineqn: growth_fun_ensemble_finite}{{15}{12}}
\newlabel{pf: growth_fun_finite_1}{{16}{12}}
\newlabel{eqn: generalization_bound_growth_number_adaboost_finite}{{17}{12}}
\citation{schapire2012boosting}
\citation{schapire2012boosting,shalev2014understanding}
\citation{shalev2014understanding}
\citation{schapire2012boosting}
\citation{schapire2012boosting}
\citation{schapire2012boosting}
\citation{schapire2012boosting}
\newlabel{eqn: pac_sample_complexity_finite_case_consistency}{{18}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Generalization Error Bounds via VC Dimension}{13}}
\newlabel{ineqn: growth_fun_ensemble_infinite}{{19}{13}}
\newlabel{ineqn: vc_dim_ensemble_infinite}{{20}{13}}
\newlabel{thm: growth_fun_adaboost}{{2.9}{13}}
\newlabel{ineqn: generalization_bound_growth_number_adaboost}{{21}{13}}
\newlabel{ineqn: pac_sample_complexity_consistency}{{22}{13}}
\citation{schapire2012boosting}
\citation{mohri2018foundations,schapire2012boosting}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\textbf  {AdaBoost may overfit if the number of rounds $T$ is too large. \citep  {schapire2012boosting}}}\relax }}{14}}
\newlabel{fig: overfitting_adaboost}{{4}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Generalization Error Bounds via Margin Theory}{14}}
\newlabel{def: l1_margin}{{23}{14}}
\citation{mohri2018foundations,schapire2012boosting}
\citation{schapire2012boosting}
\citation{schapire2012boosting}
\citation{schapire2012boosting,mohri2018foundations}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\textbf  {The piecewise linear function $\varphi _{\phi }$. \citep  {schapire2012boosting}}}\relax }}{15}}
\newlabel{fig: piecewise_linear}{{5}{15}}
\newlabel{def: l1_margin_sample}{{24}{15}}
\newlabel{eqn: emp_margin_loss}{{25}{15}}
\newlabel{eqn: emp_margin_loss_bound}{{26}{15}}
\citation{mohri2018foundations}
\citation{schapire2012boosting,mohri2018foundations}
\newlabel{eqn: rademacher_complexity}{{27}{16}}
\newlabel{eqn: rademacher_complexity_convex_hull}{{28}{16}}
\newlabel{ineqn: Rademacher_bound_1}{{29}{16}}
\newlabel{ineqn: Rademacher_bound_2}{{30}{16}}
\citation{schapire2012boosting,mohri2018foundations}
\newlabel{ineqn: Rademacher_margin_bound}{{31}{17}}
\newlabel{ineqn: Rademacher_margin_bound_2}{{32}{17}}
\newlabel{eqn: Rademacher_margin_bound_vc_dim}{{33}{17}}
\citation{schapire2012boosting}
\citation{schapire2012boosting}
\citation{schapire2012boosting,mohri2018foundations}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\textbf  {Distribution of margin for AdaBoost on one example dataset. \citep  {schapire2012boosting}}}\relax }}{18}}
\newlabel{fig: dist_margin}{{6}{18}}
\newlabel{ineqn: Rademacher_margin_bound_norm_l1}{{34}{18}}
\newlabel{ineqn: emp_margin_loss_bound}{{35}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Fundamental Perspectives}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Game Theory}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Online Learning}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Maximum Entropy Learning}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Bregman Iterative Projection Algorithms}{20}}
\bibstyle{plainnat}
\bibdata{reference.bib}
\bibcite{cesa2006prediction}{{1}{2006}{{Cesa-Bianchi and Lugosi}}{{}}}
\bibcite{thomas2006elements}{{2}{2006}{{Cover and Thomas}}{{}}}
\bibcite{hastie2009elements}{{3}{2009}{{Hastie et~al.}}{{Hastie, Tibshirani, and Friedman}}}
\bibcite{mohri2018foundations}{{4}{2018}{{Mohri et~al.}}{{Mohri, Rostamizadeh, and Talwalkar}}}
\bibcite{gabriel2019computational}{{5}{2019}{{Peyr√© and Cuturi}}{{}}}
\bibcite{schapire2012boosting}{{6}{2012}{{Schapire and Freund}}{{}}}
\bibcite{shalev2014understanding}{{7}{2014}{{Shalev-Shwartz and Ben-David}}{{}}}
