\documentclass[11pt]{article}
\usepackage[scaled=0.92]{helvet}
\usepackage{geometry}
\geometry{letterpaper,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent %\usepackage{graphicx}
\usepackage{amsmath,amssymb, amscd}
\usepackage{mathrsfs, dsfont}
\usepackage[all,cmtip]{xy}
%\diagramstyle[labelstyle=\scriptstyle]
\usepackage{tabularx}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{graphicx}
\usepackage{xcolor}
%\usepackage[linkbordercolor ={1 1 1} ]{hyperref}
%\usepackage[sf]{titlesec}
\usepackage{natbib}
\usepackage{../../Tianpei_Report}

%\usepackage{appendix}
%\usepackage{algorithm}
%\usepackage{algorithmic}

%\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%\renewcommand{\algorithmicensure}{\textbf{Output:}}



\begin{document}
\title{Summary of Gaussian process and Gaussian measure}
\author{ Tianpei Xie}
\date{ Jul. 16th., 2015 }
\maketitle
\tableofcontents
\newpage
\section{Definitions and summary}
\subsection{Measure space on infinite dimensional vector space}
\begin{itemize}
\item  \begin{definition} \citep{taylor1958introduction}\\
A \emph{topological vector space (TVS)} $X$ is a vector space equipped with a topology  on $X$ so that the vector addition and scalar product operations are both continuous. 

A complete normed linear space is called a \emph{Banach space}; A complete inner product space is called a \emph{Hilbert space}.

The \emph{(algebraic) dual} space $V^{*}$ of a vector space $V$ consists of all linear functionals on $V$ together with a naturally induced linear structure.  The \emph{continuous dual space} $X^{*}$ of a topological vector space $X$ corresponds to all continuous linear functionals, which is a subspace of (algebraic) dual space.\\ 
\end{definition}


\item \begin{definition} \citep{schaefer1999locally}\\
A topological space $X$ is \emph{locally convex Hausdorff} if it is a Hausdorff space such that every neighborhood of any $x\in E$ contains a convex neighborhood of $x$. 

Similarly, $X$ is \emph{locally compact Hausdorff  (LCH)}, if every neighborhood $U$ for every $x\in U$ has a compact neighborhood $C\subset U$, $x\in C$. 

Equivalently, a \emph{locally convex space (LCS)}  is  defined to be a vector space $V$ along with a family of \emph{seminorms} $\set{p_{\alpha}}_{\alpha\in A}$ on $V$, a semi-norm with $p_{\alpha}(u)=0 \Rightarrow u=0$ is a norm.\\
\end{definition}

\item 
\begin{definition}
Let $X$ be locally convex space, a $n$-dimensional \emph{cylinder set} as \citep{lifshits2013gaussian}
\begin{align*}
C_{A}[f_{1},\ldots, f_{n}]\equiv \set{\mb{x}\,|\, \paren{f_{1}(\mb{x}),  \ldots, f_{n}(\mb{x})} \in A\;  }, n=1,2,\ldots,
\end{align*}
for any $A\in \cB(\bR^{n})$, $A_{i}\in \cB(\bR)$, $f_{i}\in X^{*}\subset \bR^{X}$, the dual space of continuous linear functional on $X$.

The collection of $C_{A}[f_{1},\ldots, f_{n}]$ with all possible $A\in \cB(\bR^{n})$, and all $f_{i}\in X^{*}\subset \bR^{X}$ is denoted as $\srC_{n}$.
\end{definition}

\item  If the underling space is sample space $X\equiv \Omega$, then $C_{A}[\xi_{1}, \ldots, \xi_{n}]$ is a measureable set induced by a collection of random variables $\set{\xi_{t}, t\ge 1}$. \\

\item  \begin{definition}\citep{lifshits2013gaussian}\\
The collection of all cylinder sets $\srC_{n}$  for all finite dimensions $n\ge 1$ is referred as the \emph{algebra of cylinder sets}, denoted as $\srC_{0}$. That is, $\srC_{0}\equiv \bigcup_{n=1}^{\infty}\srC_{n}$, where $\srC_{n}$ is denotes as $\cB^{n}\times X^{*}\times X^{*} \times X^{*} \times \cdots$.

The collection $\srC_{0}$ forms an algebra (closed under complements and finite union).  If $X= X^{*}$, the $\srC_{0}$ is the basis for the product topology $X^{\infty}$
\end{definition} 


\item \begin{definition}
 The $\sigma$-algebra $\srC = \sigma(\srC_{0})$ generated from the algebra of cylinders $\srC_{0}$ is called \emph{cylinderical $\sigma$-algebra}. 

If $X\equiv \Omega$, with random variables $\set{\xi_{t}, t\ge 1}$, $\srC \supset \sigma(\xi_{t}, t\ge 1)$ is the sigma-algebra generated by  random variables $\set{\xi_{t}, t\ge 1}$.
 \end{definition}
 
\item \begin{definition}
The \emph{Borel $\sigma$-algebra} $\srB$ on the TVS $X$ is generated by all open/closed sets in topology of $X$.  %$X\equiv X^{\infty}$ is generated by all open sets in the form of  cylinder set 
%\begin{align*}
%\tilde{C}_{A}&= \set{\mb{x}| (x_{1}, \ldots, x_{n})\in A }
%\end{align*} 
%where $x_{k}= \pi_{k}(\mb{x})\in X_{k}$, $\pi_{k}: X \rightarrow X_{k}$ is the evaluation map to  $k$-th  coordinate.  
 \end{definition}
 
\item $\srC \subset \srB$. \\

\item Let $X$ be a (infinite dimensional) vector space. A cylindrical measure space is denoted as $(X, \srC, \mu)$, where $\mu$ is a measure on $\srC$.

In particular, $X$ is locally compact Hausdorff, and $\srC$ is the cylindrical  $\sigma$-algebra generated by all cylinder sets via continuous linear functionals on $X$, 

If $\mu$ is a \emph{Radon measure} on LCH $X$, i.e. it is \emph{inner regular} (inner approximated via compact set), \emph{outer regular} (outer approximated by open set) and \emph{locally finite} (every point is covered by an open set with finite measure), then it can be uniquely extended to the Borel $\sigma$-algebra. That is, $(X, \srB, \mu)$ is defined. \citep{lifshits2013gaussian}\\

\item \citep{folland2013real} 
A Radon measure is an extension of Lebesgue measure in $\bR^{d}$ to a LCH $X$.  A \emph{Radon measure} on a \emph{locally compact Hausdorff} space can be expressed in terms of \emph{continuous linear functionals} on the space of \emph{continuous functions with compact support}. (A Radon measure is real then it can be decomposed into the difference of two positive measures.)\\[10pt]

\item In sum, the measure space of interest is $(X, \srB, \mu)$, where $X$ is \emph{locally compact Hausdorff (LCH)} space (a topological vector space), $\srB$ is the Borel $\sigma$-algebra, including a collection $\srC_{0}$ of all cylinder sets for all continuous linear functionals on $X$, $\mu$ is a \emph{(Radon) measure} on $\srB$. 
\end{itemize}
\subsection{Random functions, dual space and Gaussian measure}
\begin{itemize}
\item Consider now the probability space $(\Omega, \srF, \bP)$, where $\Omega$ is the sample space,  $\srF$ is a $\sigma$-algebra containing $\srC_{0}$ of all cylinder sets for any family of random variables  $\xi \equiv \set{\xi_{x}, x\in E}$ on $\Omega$ 
\begin{align*}
C_{A}[\xi_{x_1},\ldots, \xi_{x_n}]\equiv \set{\omega\,|\, \paren{\xi_{x_1}(\omega),  \ldots, \xi_{x_n}(\omega)} \in A\;  }, n=1,2,\ldots,
\end{align*}for any $A\in \cB(\bR^{n})$, $\bP$ is a probability measure on $\srF$. (Assuming topology on $\Omega$, then $P$ should be a Radon measure.) \\


\item \begin{definition}\citep{lifshits2013gaussian, rasmussen2006gaussian}\\
A family of random variables $\xi_{\cdot} \equiv \set{\xi_{x}, x\in E}$ defined on $(\Omega, \srF, P)$ is called a \emph{random function}, where $E$ is the index set or input domain.  In specific, 
\begin{enumerate}
\item a \emph{random function} is a mapping $\xi_{\cdot}: E\times \Omega \rightarrow \bR$, with each finite-dimensional vector $(\xi_{x_1}, \ldots, \xi_{x_n}): (\Omega,\srF) \rightarrow (\bR^{n}, \cB(\bR^{n}))$ being measureable for every $(x_{1}, \ldots, x_{n})\subset E$, for all $n\ge 1$.

\item Also, a \emph{random function} is a measurable mapping $\Xi: (\Omega, \srF) \rightarrow (\bR^{E}, \srB)$, where $\bR^{E}= \set{f: E \rightarrow \bR}$ is the set of all functions from $E$ to $\bR$,  $\srB=\cB(\bR^{E})$ is a Borel $\sigma$-algebra  generated by the product topology on $\bR^{E}$. Here $\Xi$ is the infinite sequence as the evaluation of $\xi_{\cdot}$ at all $x\in E$, i.e.
\begin{align*}
\Xi(\omega) &\equiv \paren{\xi_{x}(\omega), x\in E}.
\end{align*}

\item  If $E\equiv T\subset \bR$, it is called a \emph{random process}, whereas for $E\subset \bR^{n}$, it is called a \emph{random field}.  

\item Assume that $E$ is a \emph{separable} metric space (i.e. $E$ has dense countable subset $E'$); without loss of generality, assume that $E$ is countable.

\item Given a sample point $\omega\in \Omega$, $\xi_{\cdot}(\omega)\in \bR^{E}$ is a real-valued function on $E$, which is called  a \emph{sample function} of the random function, or a \emph{sample path} of the random process for $T\subset \bR$.  A random function is an infinite-dimensional random vector\\[5pt]
\end{enumerate}
\end{definition}


\item \begin{definition} \citep{lifshits2013gaussian}
\begin{enumerate}
\item The induced probability on $\bR^{E}$ is given by 
\begin{align*}
\cP_{\mb{\xi}}\paren{A} &= \bP\set{\omega: (\xi_{x}(\omega), x\in E) \in A }= \bP\circ \Xi^{-1}(A); \quad \forall A\in \srB=\cB(\bR^{E})
\end{align*}
is called the \emph{distribution of random functions}, denoted as $\cP_{\mb{xi}}$. It is a probability \emph{measure} on the \emph{space of sample functions}. 

\item Given the distribution $\cP_{\mb{\xi}}$ of random functions $\xi_{x}$, the space $(\bR^{E}, \srB, \cP_{\mb{\xi}})$ can be seen as a \emph{finite measure space} on the space of functions $\bR^{E}$. 

\item For each finite-dimensional  joint  distribution $\cP_{\xi, n}$, \; $d\cP_{\xi, n} \ll dx^{n}$ is dominated by Lebesgue measure on $\bR^{n}$.  \\[5pt]
\end{enumerate}
\end{definition}


\item The \emph{dual} space $\Omega^{*}$ contains the space of  all random variables. Note that each random variable $\xi$ is a linear functional on $\Omega$, i.e. $(\xi+\eta)(\omega)= \xi(\omega)+ \eta(\omega)$. \\


\item \begin{definition} \citep{lifshits2013gaussian}\\
The \emph{barycenter} $\omega_{m}\in \Omega$ is defined for random function $\xi_{\cdot} \in L^{1}(\Omega, \bP)$ so that
\begin{align*}
\xi_{\cdot}(\omega_{m}) &= \int_{\Omega}\xi_{\cdot }(\omega) \;d\,\bP, 
\end{align*}
where the value $m_{\cdot} \equiv \xi_{\cdot}(\omega_{m})\in \bR^{E}$ is referred as the \emph{mean function (mean path)} of random function. Note that for each $x\in E$, we can find a barycenter $\omega_{m,x}$, wherease $\omega_{m}$ is the  \emph{common barycenter} for all $\xi_{x} \in L^{1}(\Omega, \bP)$ for all $x\in E$. \\
\end{definition}

\item  \begin{definition} \citep{lifshits2013gaussian}\\
The \emph{covariance operator} $K:  \Omega^{*} \rightarrow \Omega$ is a linear operator from the dual space to the sample space, so that for any  linear functionals (random variables) $\xi_{x}, \xi_{z} \in \cL^{2}(\Omega, \bP)$, then
\begin{align*}
\xi_{x}\paren{K \xi_{z}} &\equiv \int_{\Omega}\xi_{x}(\omega - \omega_{m})\xi_{z}(\omega - \omega_{m})\;d\,\bP\\
&= \int_{\Omega} (\xi_{x}(\omega) - m_{x})(\xi_{z}(\omega) - m_{z}) d\,\bP
\end{align*}
$K$ is a \emph{self-adjoint} operator, i.e. $\xi_{x}\paren{K \xi_{z}} = \xi_{z}\paren{K \xi_{x}}$.  \\[10pt]
\end{definition}

\item \begin{definition}\citep{lifshits2013gaussian}\\
A measure $\bP$ on $(\Omega, \srF)$ is \emph{Gaussian measure} if and only if for all linear functions $f\in \Omega^{*}$, the induced probability 
\begin{align*}
\cP_{f}\equiv \bP\circ f^{-1} \in \cG
\end{align*} is a Gaussian distribution on $(\bR, \cB(\bR))$; i.e. the dual $\Omega^{*}$ is the space of all  Gaussian-distributed random variables $f(\cdot): \Omega \rightarrow \bR$.
\end{definition}
\end{itemize}

\subsection{Prescribed probability space of sample functions}
\begin{itemize}
\item Now consider the \emph{induced probability space} $(F, \srB_{F}, \cP_{\mb{\xi}})$, where $F\equiv F_{\mb{\xi}}$ is the space  of all sample functions of $\mb{\xi}\equiv (\xi_{x}, x\in E)$,  $\srB_{F} = \rlat{\srB}{F}$ is the restriction of Borel $\sigma$-algebra to $F$, $\cP_{\mb{\xi}}$ is the distribution of random functions $\xi_{\cdot}$ (or, a measure of sample functions). Here, each point $f\in F$ is given as $f \equiv f_{\omega}(\cdot) = \xi(\cdot, \omega)$ for some $\omega \in \Omega$.\\

\item \begin{definition}
The \emph{distribution of a random function} $\xi$, $\cP_{\mb{\xi}}$ is a \emph{Gaussian distribution} on the induced measure space $(F, \srB_{F}, \cP_{\mb{\xi}})$, if and only if for any linear functionals $I\in F^{*}$, the induced probability (i.e. the distribution of linear functional $I$ w.r.t. $\cP_{\mb{\xi}}$) as 
\begin{align*}
\cP_{I}\equiv \cP_{\mb{\xi}}\circ I^{-1} \in \cG
\end{align*} is a Gaussian distribution on $(\bR, \cB(\bR))$.

Equivalently, $\cP_{\mb{\xi}}$ is Gaussian if and only if any finite-dimensional distribution  $\cP_{\xi, n}$ is Gaussian.\\
\end{definition}

\item \begin{definition}  \citep{lifshits2013gaussian} \\
Given the prescribed probability space $(F, \srB_{F}, \cP_{\mb{\xi}})$, where $\cP_{\mb{\xi}} \in \cG(F)$ is a Gaussian measure, it is possible to construct a space of \emph{$\cP_{\mb{\xi}}$-measureable linear functionals} $F_{P}^{*} \subset F^{*}$. In particular, 
\begin{align*}
 F^{*}&\subset \cL^{2}(F, \cP_{\mb{\xi}})\\
F_{P}^{*}&= \overline{F^{*}} \subset   \cL^{2}(F, \cP_{\mb{\xi}})\\
\text{i.e. } & \int_{F} (I(f))^{2} \;\cP_{\mb{\xi}}(df) <\infty, \quad \text{for any }I(\cdot) \in F_{P}^{*}.
\end{align*} The first statement is implied by the definition of Gaussian measure above, since the sample function $f\sim \cP_{\mb{\xi}} \in \cG(F)$ if and only if the distribution of linear functional $I(\cdot) \in F^{*}$, $P_{I}$ is a univariate Normal distribution, i.e. $P_{I}\in \cG(\bR)$. In the second statement, the closure is w.r.t. $\cL^{2}$ metric topology induced from $\cL^{2}(F, \cP_{\mb{\xi}})$.\\
\end{definition}


\item \begin{definition} \citep{lifshits2013gaussian} \\
Given the prescribed probability space $(F, \srB_{F}, \cP_{\mb{\xi}})$, where $\cP_{\mb{\xi}}$ is a measure of sample function, the \emph{kernel} of the measure $\cP_{\mb{\xi}}$ is a \emph{linear} subspace of $F$, denoted as $H_{P}$, such that 
\begin{align*}
H_{P } &\equiv \set{h\in F: \; \cP_{ah, \mb{\xi}} \ll \cP_{\mb{\xi}}, \forall a \text{ const.} }
\end{align*} where $ \cP_{h, \mb{\xi}}(A) \equiv \cP_{\mb{\xi}}(A - h)$ for any $A\in \srB_{F}$. $h\in H_{P}$ is called an \emph{admissible shift}. \\


If $\cP_{\mb{\xi}}\in \cG(F)$,  then the kernel $H_{P}$ of measure $\cP_{\mb{\xi}}$ is a Reproducing Kernel Hilbert space (RKHS) in which the covariance function is the reproducing kernel. In fact, $H_{P}\simeq F_{P}^{*}$, therefore $H_{P}$ is a Hilbert space. Also
\begin{align*}
K(F^{*}) \subseteq H_{P}&  \subseteq F,
\end{align*} where $K: F^{*} \rightarrow F$ is the covariance operator. In fact, we will show later that $H_{P}$ is a RKHS.  

Moreover, $H_{P}$ is equal to the topological support, i.e. $\cP_{\mb{\xi}}(H_{P}(K))= 1$, 
\begin{align*}
H_{P}&= \text{supp}(\cP_{\mb{\xi}})\\
&=\bigcap_{\eta \text{ degenerate}\atop I^{*}\eta=0}\set{f\in F: \eta(f)=0}
\end{align*}  where the degenerate means that $\eta: F\rightarrow \bR$ as a random variable has zero variance \\[10pt]
\end{definition}

\item \begin{definition}
Suppose given the finite measure space $(F, \srB_{F}, \cP_{\mb{\xi}})$ induced from the random function $\mb{\xi}$. If, furthermore, $F\equiv C(E)\subset \bR^{E}$ is the space of all \emph{continuous} sample functions on $E$, then
\begin{enumerate}
\item dual space $F^{*}$ is isomorphic to the space of all \emph{Baire measures} on $E$ so that for every $\eta \in F^{*}$,  a unique representation is given as 
\begin{align*}
\eta(f) &= \int_{E} f d\mu_{\eta}
\end{align*} where $\mu_{\eta}$ is the Baire measures on $(E, \srA, \nu)$ associated with $\eta$, and $\srA$ is the Borel (Baire) $\sigma$-algebra on index set $E$.\citep{reed1980methods, lifshits2013gaussian}\\

\item Define a \emph{barycenter} $f_{m}\in F$ for a $L^{1}$ linear functional $\eta \in L^{1}(F, \cP_{\mb{\xi}})$ as 
\begin{align*}
\eta(f_{m}) &= \int_{F}\eta(f) d \cP_{\mb{\xi}}, 
\end{align*} with the mean value $m_{\eta}= \eta(f_{m})$ as a linear functional $m_{\eta}(f_{m})= \eta(f_{m})$.\\ 


\item \citep{lifshits2013gaussian} \\
Define the \emph{covariance operator} $K:  F^{*} \rightarrow F$ as a linear operator from the space of $\cL^{2}$ integrable linear functionals to the function space, so that for any continuous linear functionals $\zeta, \eta \in F^{*} \subset \cL^{2}(F, \cP_{\mb{\xi}})$, then
\begin{align*}
\zeta\paren{K \eta} &\equiv \int_{F}\zeta(f - f_{m})\eta(f - f_{m})\cP_{\mb{\xi}}(df)\\
&= \int_{F} (\zeta(f) - m_{\zeta})(\eta(f) - m_{\eta})  \cP_{\mb{\xi}}(df)\\
&\text{suppose zero mean } m_{\zeta}= m_{\eta}= 0\\
&= \int_{F} \brac{\int_{E} f(t) \mu_{\zeta}(dt) \int_{E} f(s) \mu_{\eta}(ds)}\; \cP_{\mb{\xi}}(df)\\
&= \int_{E\times E} \brac{\int_{F}  f(t) f(s) \cP_{\mb{\xi}}(df)}\mu_{\zeta}(dt)\mu_{\eta}(ds)\\
&\equiv  \int_{E\times E} K(t,s)\;\mu_{\zeta}(dt)\mu_{\eta}(ds)\\
&\equiv  \zeta\paren{ \int_{E}K(\cdot,s)\mu_{\eta}(ds)  }
\end{align*} where $\mu_{\eta}, \mu_{\zeta}$ are the associated Baire measure on $E$. $K$ is a integral kernel with 
\begin{align*}
f(\cdot)\equiv (K \eta)(\cdot)&= \int_{E}K(\cdot,s)\mu_{\eta}(ds) \in F
\end{align*}

Still, $K$ is a \emph{self-adjoint} operator, i.e. $\zeta\paren{K \eta} = \eta\paren{K \zeta} $. Here the covariance of output $f_{t}= \pi_{t}(f)$ and $f_{s} = \pi_{s}(f)$ is given by 
\begin{align*}
K(t,s)&\equiv \pi_{t}\paren{K \pi_{s}} \\
&=  \int_{F}  f(t) f(s)  \cP_{\mb{\xi}}(df)= \E{\cP_{\mb{\xi}}(f)}{f(t)f(s)}
\end{align*} where $\pi_{t} , \pi_{s}$ is the evaluation functional in $F^{*}$ and $K: E \times E \rightarrow \bR$ is the associated kernel function, which is continuous on $E\times E$.

\item The reproducing property: Since $F= C(E)\subset \cL^{2}(E, \nu)$ forms a Hilbert space, then 
\begin{align*}
 F_{P}^{*} \ni \eta(g)& = \int_{E}g(s)\mu_{\eta}(ds)\quad (\text{by Riesz-Markov theorem})\\
&= \int_{E}g(s)f_{\eta}(s)\nu(ds) \quad (\text{by Riesz Representation theorem}) \\
 H_{P} \ni f_{\eta}(t)&= \int_{E}K(t,s)\mu_{\eta}\nu(ds)= \int_{E}K(t,s)f_{\eta}(s)\nu(ds),\quad \; t\in E
\end{align*} for any $f_{\eta}= I\eta =K\eta\in H_{P}$.


%\item The eigenfunction $\set{\phi_{i}, i\ge 1}$ can be defined as 
%\begin{align*}
%\phi_{i}(t)\equiv &\pi_{t}(K\eta_{i})\\
%&=  \pi_{t}\paren{ \int_{E}K(\cdot,s)\mu_{\eta_{i}}(ds)  }= \int_{E}K(t,s)\mu_{\eta_i}(ds)\\
%&\equiv \frac{1}{\lambda_{i}}\int_{E}K(t,s)\phi_{i}(s)\mu(ds)
%\end{align*} where  $\zeta\equiv \pi_{t}$, $\eta_{i}(f)= \int f \phi_{i}d\mu/ \lambda_{i}$.\\[10pt]
\end{enumerate}
\end{definition}




\end{itemize}
\subsection{The properties of Gaussian measure}
\begin{itemize}
\item The unique properties of the family of Gaussian measure $\cG(X)$ on $X$, 
\begin{enumerate}
\item Sufficient statistic: A Gaussian distribution $\cN \in \cG(X)$ is determined uniquely by the mean $m$ and covariance operator $K$.

\item Invariant under linear transformation: For $f \sim \cN \in \cG(X)$, then any linear functional $I(f)\sim \cN_{I} \in \cG(\bR)$. 

\item Invariant under translation operation:  $f\sim \cN(m, K)$, then for any $h\in \text{supp}(\cN), f+h \sim \cN(m+h, K)$.

The closure of the kernel of Gaussian measure $\overline{H_{\cN}}$ is equal to the topological support $\text{supp}(\cN)$ of the measure $\cN$.  

In general, a Borel set $A$ that is invariant w.r.t. the kernel $H_{p}$ has Gaussian measure $\cN(A)= 0$ or $\cN(A)=1$.

\item For a set of Gaussian random variables $\xi_{n} \stackrel{P}{\rightarrow} \xi$ if and only if $\xi_{n} \stackrel{L^{1}}{\rightarrow} \xi$.

\item For stationary Gaussian process, the covariance kernel has a spectral representation.

\item The unique probability measure that has maximum (differential) entropy under the second-order and first-order moment constraint is the Gaussian measure. 

\item For a Gaussian measure, the sample path is either bounded almost surely or unbounded almost surely.

\item The oscillation of a Gaussian random function (supremum of absolute difference) is equal to a constant value almost surely. In specific, it does not depend on the sample points. 
\end{enumerate}
\end{itemize}
  


\newpage
\section{Useful facts}
\begin{itemize}
\item (The \emph{standard Gaussian measure} on $\bR^{\infty}$). \citep{lifshits2013gaussian} \\
Assume a Gaussian sequence $\set{\xi_{t}, t\in \bN}$ is defined on a probability space $(\Omega, \srF, \bP)$. To construct $\cP$ on sequences in $\bR^{\infty}$, consider a mapping $\Xi: \Omega\rightarrow \bR^{\infty}$ by formula,
\begin{align*}
\Xi(\omega) &\equiv \set{\xi_{t}(\omega):  t\in \bN} \equiv \set{z_{t}, t\ge 1}\in \bR^{\infty}.
\end{align*}  Then the distribution of Gaussian sequence $\set{\xi_{t}, t\ge 1}$ is given by $\cP_{\mb{\xi}}= \bP\,\circ\, \Xi^{-1}$. In general, for any $n$-dimensional joint distribution 
\begin{align*}
P_{\mb{\xi}}(d\mb{z})\equiv d\cP_{\mb{\xi}, n}(z_{1}, \ldots, z_{n}) &= \frac{1}{\paren{2\pi}^{n/2}}\exp\set{-\frac{1}{2}\sum_{k=1}^{n}z_{k}^{2}}d\mb{z}.
\end{align*} 


The prescribed probability space of sample Gaussian sequences is $(\bR^{\infty}, \srB, \cP_{\mb{\xi}})$, where $\srB = \Xi\srF = \{A\subset \bR^{\infty}\;|\; \Xi^{-1}(A\cap \ell^{2})\in \srF \}$.  Both the \emph{topological support} and the \emph{kernel} of the Gaussian measure $\cP_{\mb{\xi}}$ is $\ell^{2}= \set{\mb{z}: \sum_{i=1}^{\infty}z_{i}^{2}< \infty}$, the most important \emph{Hilbert} space in $\bR^{\infty}$.  Also $(\ell^{2})^{*}= \ell^{2}$ is closed, so it is equivalent to define the probability space as $(\ell^{2}, \srB, \cP_{\mb{\xi}})$.

Note that by definition, the cylindrical $\sigma$-algebra $\srC$ is equal to the Borel $\sigma$-algebra $\srB$ on $\bR^{\infty}$, since the cylinder set $\set{\mb{z}\in \bR^{\infty}: (z_{1}, \ldots, z_{n})\in A }$ is the subbasis for the product topology on $\bR^{\infty}$. The distribution of $\cP_{\mb{\xi}}$ is in fact a Radon Gaussian measure.

We have
\begin{align*}
m_{t} &= \int_{\Omega} \xi_{t}(\omega) d\bP= \int_{\ell^{2}} z_{t} P_{\mb{\xi}}(d\mb{z})\\
& = 0\\
\text{cov}(\xi_{t}, \xi_{s}) \equiv \xi_{t}(K\xi_{s}) &= \int_{\Omega}\paren{\xi_{t}(\omega)- m_{t}}\paren{\xi_{s}(\omega)- m_{s}}d\bP\\
&= \int_{\ell^{2}}\paren{z_{t}- m_{t}}\paren{z_{s}- m_{s}}P_{\mb{\xi}}(d\mb{z})\\
&= \delta_{s}(t) = \left\{\begin{array}{cc}
1 & s= t\\
0 & s\neq t 
\end{array} 
 \right.
\end{align*}

The dual space $(\bR^{\infty})^{*}$ has basis as $\set{\pi_{k}, k\ge 1 }$, where $\pi_{k}(\mb{z})= z_{k}$ is the evaluation map.  In particular, for any $\cP_{\mb{\xi}}$-measureable linear functional $z(\cdot)\in  (\bR^{\infty})_{P}^{*}\equiv\overline{(\bR^{\infty})^{*}}\subset \cL^{2}(\bR^{\infty}, \cP_{\mb{\xi}})$, we have 
\begin{align}
z(\cdot) &= \sum_{k=1}^{\infty}z_{k}\,\pi_{k}(\cdot),\quad \sum_{k=1}^{\infty}z_{k}^{2}< \infty.
\end{align}
Each functional $z$ is in fact in $\ell^{2}= \overline{(\bR^{\infty})^{*}}= (\bR^{\infty})_{P}^{*}$ by assumption that $\cP_{\mb{\xi}}\in \cG(\bR^{\infty})$. In specific, $z$ yields a \emph{univariate Normal distribution} $P_{z}=\cN(0, \sum_{k}z_{k}^{2})$ with respect to the measure $\cP_{\mb{\xi}}$. $P_{z}$ is a probability measure on $\cB(\bR)$.

The adjoint operator $I: (\bR^{\infty})^{*}\rightarrow \bR^{\infty}$ is just the natural mapping which translates each functional $z=\sum_{j\in \bN}z_{j}\,\pi_{k}$ into sequence of $\set{z_{j}, j\in \bN }$. And, the embedding mapping $I^{*}: (\bR^{\infty})^{*} \rightarrow (\bR^{\infty})_{P}^{*} \Leftrightarrow \ell^{2} \rightarrow  \ell^{2}$ is an identity map, since $(\ell^{2})^{*}$ is closed.\\[10pt]


\item (The Gaussian measure in Hilbert space $X$). \\
Let $X$ be a separable Hilbert space, and $\set{\mb{e}_{k}}_{k=1}^{\infty}$ be a basis in $X$. Let $\set{w_{k}}$ a sequence of \emph{independent} $\cN(0,1)$-distributed random variables defined in probability space $(\Omega, \srF, \bP)$. In other word, $\set{w_{k}}$ is a standard Gaussian sequence in $(\ell^{2}, \srB_{w}, \cW)$.  Finally let $\set{\sigma_{k}}$ be a sequence of nonegative numbers with 
\begin{align*}
\sum_{k=1}^{\infty}\sigma^{2}_{k} \le \infty.
\end{align*} Define a mapping $\Xi: \Omega\rightarrow X$ by formula
\begin{align}
\Xi(\omega) &= \mb{a}+ \sum_{k=1}^{\infty}\sigma_{k}w_{k}(\omega)\mb{e}_{k},
\end{align} where $\mb{a}\in X$ is a constant (function). Here $\Xi$ is a random function in $X$ with $\mb{\eta}\equiv \Xi(\omega)$ a sample path.

Then $\cP_{\mb{\xi}} = \bP\,\circ\,\Xi^{-1}\in \cG(X)$ is the Gaussian measure on $X$. In specific, let $\mb{a}=0$ for $P\in \cG_{0}(X)$ to be a centered Gaussian measure on  $X$. The prescribed probability space is given as $(X, \srB, \cP_{\mb{\xi}})$. The Gaussian measure $\cP_{\mb{\xi}}$ is a Radon measure on the Borel $\sigma$-algebra $\srB$ of $X$ and it can be shown that \emph{any} Gaussian measure in $X$ may be built using this construction. 

To construct the space of all $\cP_{\mb{\xi}}$-measureable linear functionals $X_{P}^{*}\subset X^{*}$, we see that, due to the Riesz representation theorem, the space $X^{*}$ dual to a Hilbert space consists of linear functionals of the form
\begin{align*}
I(\cdot) &= \sum_{k=1}^{\infty}I_{k}\inn{\cdot}{\mb{e}_{k}}, \quad \sum_{k=1}^{\infty}I_{k}^{2}< \infty,
\end{align*} where $\mb{\eta}\in X$ is a sample path. 
Take the closure of $X^{*}$ in $\cL^{2}(X, \cP_{\mb{\xi}})$ to obtain $X_{P}^{*}$, which consists of the functional of the form
\begin{align}
\zeta(\cdot) &=  \sum_{k=1}^{\infty}\zeta_{k}\inn{\cdot}{\mb{e}_{k}}_{\cL^{2}(\cP_{\mb{\xi}})}, \quad \sum_{k=1}^{\infty}\zeta_{k}^{2}\sigma_{k}^{2}< \infty,
\end{align}
where the inner product in $X_{P}^{*}$ is given as 
\begin{align*}
\inn{\zeta_{1}(\cdot)}{\zeta_{2}(\cdot)}_{X_{P}^{*}} &= \int \zeta_{1}(\mb{\eta})\zeta_{2}(\mb{\eta})P_{\mb{\xi}}(d\mb{\eta})\\
&= \sum_{k=1}^{\infty}\sigma_{k}^{2}\;\zeta_{k,1}\zeta_{k,2}.
\end{align*} The distribution of functional $\zeta(\cdot) = \sum_{k=1}^{\infty}\zeta_{k}\inn{\cdot}{\mb{e}_{k}} $ w.r.t. $\cP_{\mb{\xi}}$ is $\cN(0, \sum_{k=1}^{\infty}\zeta_{k}^{2}\sigma_{k}^{2})$ on $\cB(\bR)$. 

The topological support $\text{supp}(P) = H_{P}=\set{h\in X: h \text{ is an admissible shift of }\cP_{\mb{\xi}}}$ is the whole space $X$ where $\cP_{\mb{\xi}}$ is defined.\\[10pt]


\item  (The Gaussian measure in Reproducing Kernel Hilbert space $X$). \\
Consider the space $\cH$ of the sample functions is a Reproducing Kernel Hilbert space on $E$, associated with kernel function $K: E\times E\rightarrow \bR$. Let $\set{\phi_{i}(\cdot), i\ge 1}$ be the eigenfunctions of $K$ w.r.t. measure $\mu$, where $\phi_{j}$ is associated with eigenvalue $\lambda_{j}$ and for $\set{\lambda_{i}(\cdot), i\ge 1}$
\begin{align*}
\lambda_{i}\phi_{i}(x) &= \inn{K(\cdot, x)}{\phi_{i}}= \int_{\cX}\phi_{i}(z)K(z,x)d\mu(z), \forall x\in E\\
&\sum_{i=1}^{\infty}\lambda_{i} <\infty; \quad  \lambda_{j}\ge 0, j\ge 1.
\end{align*}
The collection of eigenfunctions  $\set{\phi_{i}(\cdot), i\ge 1}$ forms an orthogonal basis for $\cH$, such that for any sample function $f: E \rightarrow \bR$, $f\in \cH$,
\begin{align*}
f(\cdot)&= \sum_{i=1}^{\infty}f_{i}\phi_{i}(\cdot)
\end{align*}
Moreover,  the following property holds
\begin{align*}
f(x)&= \inn{f}{K(\cdot, x)}_{\cH}. \quad (\text{reproducing property})\\
\text{where} & \inn{f}{g}_{\cH} = \sum_{i=1}^{\infty}\frac{f_{i}g_{i}}{\lambda_{i}} = \inn{K^{-1}f}{g}, \\  
K(x,x') &= \sum_{i=1}^{\infty}\lambda_{i}\phi_{i}(x)\phi_{i}(x') \quad (\text{Mercer's theorem})\\
f(\cdot)&=\sum_{m}\widehat{\beta}_{m}K(\cdot, x_{m}) \quad (\text{Representor's theorem})
\end{align*} Now define the random function $\Xi: \Omega\rightarrow \cH$ is given by formula
\begin{align}
\Xi(\omega) &=  \sum_{i}w_{i}(\omega)\sqrt{\lambda_{i}}\phi_{i}(\cdot), \quad \sum_{i=1}^{\infty}w_{i}^{2} <\infty,  
\end{align} where $\set{w_{i}, i\ge 1}$ is a standard Gaussian sequence on $(\Omega, \srF, \bP)$, i.e. it follows a White noise measure $\cW$ on $\ell^{2}\subset \bR^{\infty}$. The probability measure of sample functions in $\cH$ is defined as $\cP_{\mb{\xi}}= \bP\,\circ\, \Xi^{-1}$. The prescribed probability space is $(\cH, \srB_{\cH}, \cP_{\mb{\xi}})$. 

We can construct the space of all $\cP_{\mb{\xi}}$-measureable linear functionals $\cH_{P}^{*}\subset \cH^{*}\simeq \cH$, due to the Riesz representation theorem, any $I\equiv I_{\eta} \in \cH_{P}^{*}$ then
\begin{align*}
I_{\eta}(\cdot) &= \inn{\cdot}{\eta}_{\cH} = \sum_{i}\eta_{i}\inn{\cdot}{\phi_{i}}_{\cH} = \sum_{n}\widehat{\alpha}_{n}\inn{\cdot}{K(\cdot, x_{n})} \\
&\in \cL^{2}(\cH, \cP_{\mb{\xi}})\\
&\Rightarrow   \sum_{i=1}^{\infty}\eta_{i}^{2}/\lambda_{i}<\infty
\end{align*}
%where $f= \sum_{i}w_{i}\sqrt{\lambda_{i}}\phi_{i}$ is $\cP_{\mb{\xi}}$-measureable function in $\cH$.
In other word, the distribution of $I_{\eta}$, $P_{I} = \cN(0, \sum_{i=1}^{\infty}\eta_{i}^{2}/\lambda_{i})$ on $\cB(\bR)$.

For the covariance operator $K: \cH_{P}^{*}\simeq \cH \rightarrow \cH$, and for any $\xi, \eta \in \cH^{*} \simeq \cH $,  the following equality holds,
\begin{align}
\xi\paren{ K(\eta ) } &= \int_{\cH}\xi(f-m)\eta(f-m)\cP_{\mb{\xi}}(df) \nonumber
\end{align} 

Note that $\xi(f) \equiv f(x_{\xi})= \inn{f}{K(\cdot, x_{\xi})}_{\cH}\in \cH^{*}$ and $\eta(f)\equiv f(x_{\eta})= \inn{f}{K(\cdot, x_{\eta})}_{\cH} \in \cH^{*}$ are two functionals on $\cH$. Therefore,
\begin{align*}
&cov(f(x_{\xi}), f(x_{\eta})) \equiv \xi\paren{ K(\eta ) }\\
&= \int_{\cH}\xi(f)\eta(f)\cP_{\mb{\xi}}(df) \nonumber\\
&=  \int_{\cH}\inn{f}{K(\cdot, x_{\xi})}_{\cH}\inn{f}{K(\cdot, x_{\eta})}_{\cH}\cP_{\mb{\xi}}(df)\\
&= \int_{\ell^{2}}\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} \brac{\sqrt{\lambda_{i}}w_{i}\inn{\phi_{i}}{K(\cdot, x_{\xi})}_{\cH}}\brac{\sqrt{\lambda_{j}}w_{j}\inn{\phi_{j}}{K(\cdot, x_{\eta})}_{\cH}} \cW(d\mb{w})\\
&=\sum_{i=1}^{\infty} \sum_{j=1}^{\infty} \paren{ \sqrt{\lambda_{i}} \sqrt{\lambda_{j}} \int_{\ell^{2}}w_{i}w_{j}\cW(d\mb{w})}\phi_{i}(x_{\xi})\phi_{j}(x_{\eta})\\
&= \sum_{i=1}^{\infty} \sum_{j=1}^{\infty}\lambda_{i}\delta_{i}(j)\,\phi_{i}(x_{\xi})\phi_{j}(x_{\eta})\\
&= \sum_{i=1}^{\infty}\lambda_{i}\phi_{i}(x_{\xi})\phi_{i}(x_{\eta})\\
&= K(x_{\xi}, x_{\eta})
\end{align*} where $d\cW(\mb{w})= \cN(0,I)d\mb{\mb{w}}$ so that $\sum_{i=1}^{\infty}w_{i}^{2}<\infty$. In other word, the covariance between two outputs is determined by the kernel function on their corresponding inputs.

\item \begin{remark}
For a general locally convex Hausdorff space $X=C(T)$ of sample functions, where $T$ is (metric) separable, the probability space is $(X, \srA, \cP)$, where $\cP$ is induced by some linear mapping $J: X^{*} \rightarrow M(\Omega, \srF, \bP)$, for the linear space of random variables on $(\Omega, \srF, \bP)$, i.e. any linear functional in $X^{*}$ is a random variable, the joint distribution of output of $f$ is given as 
\begin{align*}
\cP\set{f:  (I_{1}(f), \ldots, I_{n}(f))\in A }  &=\bP\brac{ (J(I_{1}), \ldots, J(I_{n}))\in A }.
\end{align*}

The topological support $H_{P}$ of $\cP$ is a RKHS in $X$, which is associated with the continuous covariance function $K: E\times E \rightarrow \bR$ as defined above. In fact
\begin{align*}
\cP\set{ f\in H_{P} } = 1 \text{ or } 0.\\[10pt]
\end{align*}
\end{remark}


 \item Two operators 
\begin{enumerate}
\item \begin{definition}
The \emph{canonical embedding operator} $I^{*}: F^{*} \rightarrow F_{P}^{*}\subset \cL^{2}(F, \cP_{\mb{\xi}}):  I^{*}(f) = f,$ if $f\in F_{P}^{*}$. Note that $F^{*}\subset \cL^{2}(F, \cP_{\mb{\xi}})$, since for each realization $f\in F$ of Gaussian random function, by definition, its linear functionals $I(f)$ has finite variance for all $\eta \in F^{*}$; i.e. 
\begin{align*}
\norm{\eta}{2} &= \paren{\int_{f} \abs{\eta(f)}^{2} \cP_{\mb{\xi}}(df)}^{1/2} <\infty.
\end{align*} If $\cP_{\mb{\xi}}$ is not centered, $I^{*}(f) = f- m\,\mb{1}$, here $\mb{1}$ is constant function and $I^{*}(F^{*})$ is the space of all centered linear functionals. $I^{*}$ is continuous under weak topology $\srT_{\overline{F}, F^{*}}$
\end{definition}

\item \begin{definition}
The \emph{adjoint operator} $I: F_{P}^{*} \rightarrow F$ so that for any  linear functionals $\zeta\in F^{*}$, $\eta\in F_{P}^{*}$
\begin{align*}
\zeta\paren{I \eta} &=\inn{\eta}{I^{*}\zeta}_{\cL^{2}(F)}\\
&= \int_{F}\eta(f)\; (I^{*}\zeta)(f)\cP_{\mb{\xi}}(df)
\end{align*}
\end{definition}

\item For Gaussian measure $\cP_{\mb{\xi}}\in \cG(F)$, the kernel of measure $\cP_{\mb{\xi}}$ is the domain of $I$ under $\cP_{\mb{\xi}}$-measureable linear functionals,  i.e., $$H_{P}= I(F_{P}^{*})$$.

The domain of adjoint operator $I: F_{P}^{*} \rightarrow I(F_{P}^{*})= H_{P} \subset F$ is an isomorphism. 

\item The covariance operator $$K= II^{*}:  F^{*} \rightarrow F$$

That is, 
\begin{align*}
K(F^{*}) \subseteq H_{P}&\subseteq F
\end{align*}
\end{enumerate}


\item Some other operators: given any Hilbert space $L$, 
\begin{enumerate}
\item define $J: L \rightarrow F$ as a linear operator and the kernel $H_{P}= J(L)$. 

\item define its adjoint $J^{*}: F^{*} \rightarrow L$

\item the kernel can be decomposed as $K = J\,J^{*}$

\item the variance of linear functional $\eta$, is given as
\begin{align*}
\norm{\eta}{\cL^{2}(F,\cP_{\xi})} &= \norm{\xi}{L}
\end{align*}
where $\xi\in J^{-1}(h_{\eta})$, $h_{\eta}= I\eta$.

\item In fact, if $L= \cL^{2}(\Omega, \srF, \bP)$ is the space of random variables with finite variance on $(\Omega, \srF, \bP)$, then we can generate the sample function via equation 
\begin{align*}
f(\omega) &= J(\xi(\omega)),\;\; \omega\in \Omega
\end{align*}
 for random variables $\xi \in L$.

\item Also, define $L = \cL^{2}(S, \srM, \nu)$ to be Hilbert space of functions on domain $S$, with a set of basis function $\set{m_{t}, t\in E}$. $L$ is considered as a generalized spectral representation with
\begin{align*}
J^{*}\paren{\int_{E} (\cdot) \mu_{\eta}(dt) }(r) &= \int_{E}m_{t}(r)\mu_{\eta}(dt)\equiv m_{\eta}(r)\\
f_{\eta}(s)\equiv (J\,m_{\eta})(s) &= \inn{m_{\eta}}{m_{s}}_{L}= \int_{E}\paren{\int_{S}m_{t}(u)m_{s}(u)\nu(du) } \mu_{\eta}(dt)\\
&= \int_{E}K(t,s)\mu_{\eta}(dt)\\
K(t,s) &= \int_{S}m_{t}(u)m_{s}(u)\nu(du)
\end{align*}
\end{enumerate}


\end{itemize}
\newpage
\bibliographystyle{plainnat}
\bibliography{reference.bib}
\end{document}