\relax 
\citation{sutton2018reinforcement}
\citation{sutton2018reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\textbf  {Markov Decision process formulation}. \citep  {sutton2018reinforcement}}\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: mdp}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Markov Decision Process}{2}}
\newlabel{eqn: expected_rewards_state_action}{{1}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Goals and Rewards}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Returns and Episodes}{4}}
\newlabel{eqn: discount_return}{{2}{4}}
\newlabel{eqn: return}{{3}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Policies and Value Functions}{5}}
\newlabel{eqn: value_fun}{{4}{5}}
\newlabel{eqn: value_action_state_fun}{{5}{5}}
\newlabel{eqn: value_fun_by_value_action2}{{6}{5}}
\newlabel{eqn: value_fun_by_value_action}{{7}{5}}
\newlabel{eqn: value_action_fun_by_value}{{8}{6}}
\newlabel{eqn: value_action_fun_by_value2}{{9}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Bellman equation}{6}}
\newlabel{eqn: bellman_eqn_value_action}{{10}{6}}
\newlabel{eqn: bellman_eqn_value_action2}{{11}{6}}
\citation{sutton2018reinforcement}
\citation{sutton2018reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\textbf  {backup diagram}. \citep  {sutton2018reinforcement}}\relax }}{7}}
\newlabel{fig: backup_diagram}{{2}{7}}
\newlabel{eqn: bellman_eqn_value}{{12}{7}}
\newlabel{eqn: bellman_eqn_value2}{{13}{7}}
\newlabel{eqn: bellman_eqn_value3}{{14}{7}}
\newlabel{eqn: bellman_eqn_value_action2}{{15}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Optimal Policy and Optimal Value Function}{8}}
\newlabel{eqn: optimal_val}{{16}{8}}
\newlabel{eqn: optimal_action_val}{{17}{8}}
\newlabel{eqn: optimal_action_val2}{{18}{8}}
\newlabel{eqn: bellman_eqn_optimal_value1}{{19}{8}}
\newlabel{eqn: bellman_eqn_optimal_value2}{{20}{8}}
\newlabel{eqn: bellman_eqn_optimal_value3}{{21}{8}}
\citation{sutton2018reinforcement}
\citation{sutton2018reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8\p@ plus2\p@ minus4\p@ \abovedisplayshortskip \z@ plus\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {\textbf  {backup diagram for $v_{*}$ and $q_{*}$}. \citep  {sutton2018reinforcement}}\relax }}{9}}
\newlabel{fig: backup_diagram_bellman_opt}{{3}{9}}
\newlabel{eqn: bellman_eqn_optimal_value_action3}{{22}{9}}
\newlabel{eqn: bellman_eqn_optimal_value_action}{{23}{9}}
\newlabel{eqn: bellman_eqn_optimal_value_action2}{{24}{9}}
\bibstyle{plainnat}
\bibdata{reference.bib}
\bibcite{sutton2018reinforcement}{{1}{2018}{{Sutton and Barto}}{{}}}
