# Reinforcement Learning

## Books

***Reinforcement Learning-An Introduction***, Richard S. Sutton and Andrew G. Barto, 2nd Edition

***Markov Decision Processes Discrete Stochastic Dynamic Programming***, Martin L. Puterman


## Table of Content

- Summary

- Tabluar-Based Methods
  - Multi-Armed Bandit Problem
    - Exploration and Exploitation
    - Action-Value Methods
    - Nonstationary Problem
    
  - Markov Decision Process (MDP)
    - Goal and Rewards
    - Average Rewards
    - Bellman Equation
    - Optimal Policy and Optimal Value Function, Bellman optimality equations

  - Dynamic Programming
    - Policy Evaluation (Prediction)
    - Policy Iteration (Control)
    - Value Iteration
    - Generalized Policy Iteration
  
  - Monte Carlo Methods
    - Monte Carlo Methods for Prediction
    - Monte Carlo Methods for Control
    - On-Policy and Off-Policy Learning Without Exploring Starts
    - Off-Policy Monte Carlo Control

  - Temporal-Difference Learning
    - Temporal-Difference Prediction 
    - Temporal-Difference Control 
      - SARSA
      - Q-Learning 
      - Expected SARSA
 
  - Planning and Learning with Tabular Methods
    - Models and Planning
    - Dyna: Integrated Planning, Acting, and Learning
 
- Function Approximation
  - On-policy Prediction with Function Approximation
    - Value-Function Approximation as Supervised Learning
    - Stochastic Gradient and Semi-Gradient Methods
    - Linear Methods 
    - Value Function Approximation via Artificial Neural Networks

  - Control with Function Approximation
    - Episodic Semi-Gradient Control
    - Average Rewards as New Problem Setting for Continuing Tasks
 
  - Policy Gradient Methods
    - Value-based methods vs. Policy-based methods
    - Policy Approximation 
    - The Policy Gradient Theorem
    - REINFORCE: Monte Carlo Policy Gradient
    - Actor-Critic Methods
  - 
