\contentsline {section}{\numberline {1}Information Theory Basics}{2}
\contentsline {subsection}{\numberline {1.1}Entropy, Relative Entropy, and Mutual Information}{2}
\contentsline {section}{\numberline {2}Information Inequalities}{2}
\contentsline {subsection}{\numberline {2.1}Chain Rules for Entropy, Relative Entropy, and Mutual Information}{2}
\contentsline {subsection}{\numberline {2.2}Han's Inequality}{2}
\contentsline {subsection}{\numberline {2.3}Sub-Additivity of Entropy and Relative Entropy}{2}
\contentsline {subsection}{\numberline {2.4}Duality and Variational Formulas}{2}
\contentsline {subsection}{\numberline {2.5}Optimal Transport}{2}
\contentsline {subsection}{\numberline {2.6}Pinsker's Inequality}{2}
\contentsline {subsection}{\numberline {2.7}The Brunn-Minkowski Inequality}{2}
